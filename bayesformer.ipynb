{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning Moses github repository (for tokenization scripts)...\n",
      "Cloning into 'mosesdecoder'...\n",
      "remote: Enumerating objects: 148464, done.\u001b[K\n",
      "remote: Counting objects: 100% (892/892), done.\u001b[K\n",
      "remote: Compressing objects: 100% (367/367), done.\u001b[K\n",
      "remote: Total 148464 (delta 567), reused 802 (delta 521), pack-reused 147572 (from 1)\u001b[K\n",
      "Receiving objects: 100% (148464/148464), 129.99 MiB | 13.17 MiB/s, done.\n",
      "Resolving deltas: 100% (114593/114593), done.\n",
      "Cloning Subword NMT repository (for BPE pre-processing)...\n",
      "Cloning into 'subword-nmt'...\n",
      "remote: Enumerating objects: 622, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
      "remote: Total 622 (delta 25), reused 31 (delta 16), pack-reused 576 (from 1)\u001b[K\n",
      "Receiving objects: 100% (622/622), 261.27 KiB | 1.45 MiB/s, done.\n",
      "Resolving deltas: 100% (374/374), done.\n",
      "Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n",
      "--2025-01-22 13:14:42--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n",
      "Resolving wit3.fbk.eu (wit3.fbk.eu)... 142.250.74.147, 2a00:1450:400f:805::2013\n",
      "Connecting to wit3.fbk.eu (wit3.fbk.eu)|142.250.74.147|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2025-01-22 13:14:43 ERROR 404: Not Found.\n",
      "\n",
      "Data not successfully downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the data\n",
    "!bash venv/lib/python3.8/site-packages/fairseq/examples/translation/prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:49:13 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "2025-01-21 20:49:13 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/iwslt14.tokenized.de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='examples/translation/iwslt14.tokenized.de-en/train', use_plasma_view=False, user_dir=None, validpref='examples/translation/iwslt14.tokenized.de-en/valid', wandb_project=None, workers=20)\n",
      "2025-01-21 20:49:17 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n",
      "2025-01-21 20:49:28 | INFO | fairseq_cli.preprocess | [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced (by <unk>)\n",
      "2025-01-21 20:49:28 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n",
      "2025-01-21 20:49:29 | INFO | fairseq_cli.preprocess | [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced (by <unk>)\n",
      "2025-01-21 20:49:29 | INFO | fairseq_cli.preprocess | [de] Dictionary: 8848 types\n",
      "2025-01-21 20:49:30 | INFO | fairseq_cli.preprocess | [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced (by <unk>)\n",
      "2025-01-21 20:49:30 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n",
      "2025-01-21 20:49:43 | INFO | fairseq_cli.preprocess | [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced (by <unk>)\n",
      "2025-01-21 20:49:43 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n",
      "2025-01-21 20:49:44 | INFO | fairseq_cli.preprocess | [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced (by <unk>)\n",
      "2025-01-21 20:49:44 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6632 types\n",
      "2025-01-21 20:49:45 | INFO | fairseq_cli.preprocess | [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced (by <unk>)\n",
      "2025-01-21 20:49:45 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"
     ]
    }
   ],
   "source": [
    "# Preprocess/binarize the data\n",
    "!TEXT=examples/translation/iwslt14.tokenized.de-en && \\\n",
    "fairseq-preprocess --source-lang de --target-lang en \\\n",
    "    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "    --destdir data-bin/iwslt14.tokenized.de-en \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')\n",
      "2025-01-22 10:23:14 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types\n",
      "2025-01-22 10:23:14 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types\n",
      "2025-01-22 10:23:14 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n",
      "2025-01-22 10:23:14 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n",
      "2025-01-22 10:23:14 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8848, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(6632, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=6632, bias=False)\n",
      "  )\n",
      ")\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | num. model params: 39469056 (num. trained: 39469056)\n",
      "2025-01-22 10:23:14 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2025-01-22 10:23:14 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n",
      "2025-01-22 10:23:14 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt\n",
      "2025-01-22 10:23:14 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2025-01-22 10:23:14 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de\n",
      "2025-01-22 10:23:14 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en\n",
      "2025-01-22 10:23:14 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n",
      "epoch 001:   0%|                                       | 0/1101 [00:00<?, ?it/s]2025-01-22 10:23:16 | INFO | fairseq.trainer | begin training epoch 1\n",
      "/home/sondre/fairseq/.venv/lib/python3.8/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "epoch 001:   0%|                             | 3/1101 [00:19<2:00:25,  6.58s/it]^C\n"
     ]
    }
   ],
   "source": [
    "# train a Transformer translation model over this data\n",
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
    "    data-bin/iwslt14.tokenized.de-en \\\n",
    "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairseq                  0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sondre/fairseq/venv/bin/fairseq-train\", line 5, in <module>\n",
      "    from fairseq_cli.train import cli_main\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq_cli/train.py\", line 19, in <module>\n",
      "    from fairseq import (\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/__init__.py\", line 19, in <module>\n",
      "    import fairseq.criterions  # noqa\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/criterions/__init__.py\", line 13, in <module>\n",
      "    from fairseq.criterions.fairseq_criterion import (  # noqa\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/criterions/fairseq_criterion.py\", line 9, in <module>\n",
      "    from fairseq import metrics, utils\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/utils.py\", line 20, in <module>\n",
      "    from fairseq.data import iterators\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/data/__init__.py\", line 23, in <module>\n",
      "    from .indexed_dataset import (\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/fairseq/data/indexed_dataset.py\", line 101, in <module>\n",
      "    6: np.float,\n",
      "  File \"/home/sondre/fairseq/venv/lib/python3.8/site-packages/numpy/__init__.py\", line 305, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'float'.\n",
      "`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# modified to align with hyperparameter from paper\n",
    "# train a Transformer translation model over this data\n",
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
    "    data-bin/iwslt14.tokenized.de-en \\\n",
    "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
    "    --criterion label_smoothed_cross_entropy \\\n",
    "    --max-tokens 4096 \\\n",
    "    --max-update 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/sondre/fairseq/fairseq_cli/train.py\", line 30, in <module>\n",
      "    from fairseq import checkpoint_utils, options, quantization_utils, tasks, utils\n",
      "  File \"/home/sondre/fairseq/fairseq/__init__.py\", line 33, in <module>\n",
      "    import fairseq.criterions  # noqa\n",
      "  File \"/home/sondre/fairseq/fairseq/criterions/__init__.py\", line 36, in <module>\n",
      "    importlib.import_module(\"fairseq.criterions.\" + file_name)\n",
      "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/sondre/fairseq/fairseq/criterions/ctc.py\", line 20, in <module>\n",
      "    from fairseq.data.data_utils import post_process\n",
      "  File \"/home/sondre/fairseq/fairseq/data/__init__.py\", line 24, in <module>\n",
      "    from .indexed_dataset import (\n",
      "  File \"/home/sondre/fairseq/fairseq/data/indexed_dataset.py\", line 15, in <module>\n",
      "    from fairseq.data.huffman import HuffmanMMapIndexedDataset, HuffmanMMapIndex\n",
      "  File \"/home/sondre/fairseq/fairseq/data/huffman/__init__.py\", line 6, in <module>\n",
      "    from .huffman_coder import HuffmanCodeBuilder, HuffmanCoder\n",
      "  File \"/home/sondre/fairseq/fairseq/data/huffman/huffman_coder.py\", line 11, in <module>\n",
      "    from bitarray import bitarray, util\n",
      "ModuleNotFoundError: No module named 'bitarray'\n"
     ]
    }
   ],
   "source": [
    "# train a Transformer translation model over this data\n",
    "!CUDA_VISIBLE_DEVICES=0 python3.8 -m fairseq_cli.train \\\n",
    "    data-bin/iwslt14.tokenized.de-en \\\n",
    "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
