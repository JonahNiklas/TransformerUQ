{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = nn.GELU(approximate='tanh')\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024 # max sequence length\n",
    "    vocab_size: int = 50257 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 12 # number of layers\n",
    "    n_head: int = 12 # number of heads\n",
    "    n_embd: int = 768 # embedding dimension\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing scheme\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # init params\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is of shape (B, T)\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
    "        # forward the token and posisition embeddings\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        # forward the blocks of the transformer\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        # forward the final layernorm and the classifier\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpt2 = GPT.from_pretrained('gpt2').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Hello, I'm a language model, that you have got the capability of thinking about what I wrote up on the web. Now, by extension, this is\n",
      "sample 1: Hello, I'm a language model, a framework for programming. I'm also a scientist.\"\n",
      "\n",
      "He smiled and looked up at me. \"How did\n",
      "sample 2: Hello, I'm a language model, and I'm gonna use the language model.\"\n",
      "\n",
      "A lot of the people at Google thought about such questions. And\n",
      "sample 3: Hello, I'm a language model, there is a lot of work involved in developing that language, I wanted to do it myself, the only thing I have\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = \"cuda\" if \"cuda\" in device else \"cpu\"\n",
    "\n",
    "def generate_from_model(model, context, max_tokens=100):\n",
    "    model.eval()\n",
    "    num_return_sequences = 4\n",
    "    max_length = 32\n",
    "    tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "    xgen = tokens.to(device)\n",
    "    sample_rng = torch.Generator(device=device)\n",
    "    pbar = tqdm(total=max_length - xgen.size(1), desc=\"Generating\")\n",
    "    while xgen.size(1) < max_length:\n",
    "        # forward the model to get the logits\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "                logits, loss = model(xgen) # (B, T, vocab_size)\n",
    "            # take the logits at the last position\n",
    "            logits = logits[:, -1, :] # (B, vocab_size)\n",
    "            # get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # do top-k sampling of 50 (huggingface pipeline default)\n",
    "            # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "            # select a token from the top-k probabilities\n",
    "            # note: multinomial does not demand the input to sum to 1\n",
    "            ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "            # gather the corresponding indices\n",
    "            xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "            # append to the sequence\n",
    "            xgen = torch.cat((xgen, xcol), dim=1)\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    # print the generated text\n",
    "    for i in range(num_return_sequences):\n",
    "        tokens = xgen[i, :max_length].tolist()\n",
    "        decoded = enc.decode(tokens)\n",
    "        print(f\"sample {i}: {decoded}\")\n",
    "\n",
    "\n",
    "generate_from_model(gpt2, \"Hello, I'm a language model,\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81785cd6d78b4702a799e78f19a9e521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating HellaSwag:   0%|          | 0/10042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 294\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal/uncertainty_list.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    292\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(uncertainty_list, f)\n\u001b[0;32m--> 294\u001b[0m \u001b[43mevaluate_hellaswag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 274\u001b[0m, in \u001b[0;36mevaluate_hellaswag\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    272\u001b[0m     pred_norm \u001b[38;5;241m=\u001b[39m get_most_likely_row(tokens, mask, logits)\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# Compute uncertainty via MC dropout for the selected candidate row.\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     uncertainty \u001b[38;5;241m=\u001b[39m \u001b[43mget_uncertainty_of_selected_tokens_mcdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_norm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_norm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m num_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    276\u001b[0m num_correct_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(pred_norm \u001b[38;5;241m==\u001b[39m label)\n",
      "Cell \u001b[0;32mIn[20], line 236\u001b[0m, in \u001b[0;36mget_uncertainty_of_selected_tokens_mcdo\u001b[0;34m(model, tokens, mask, num_mc_samples)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_mc_samples):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# Perform a forward pass (dropout is active because model is in training mode)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m         logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# logits has shape: (1, T, vocab_size)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Remove the batch dimension, now (T, vocab_size)\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     log_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (T, vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 120\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# forward the blocks of the transformer\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 120\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# forward the final layernorm and the classifier\u001b[39;00m\n\u001b[1;32m    122\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 66\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mCausalSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m B, T, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;66;03m# batch size, sequence length, embedding dimensionality (n_embd)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# calculate query, key, values for all heads in batch and move head forward to be the batch dim\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_embd, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     32\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(B, T, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# (B, nh, T, hs)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/TransformerUQ/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloads and evaluates HellaSwag in Python.\n",
    "https://github.com/rowanz/hellaswag\n",
    "\n",
    "Example HellaSwag json item:\n",
    "\n",
    "{\"ind\": 24, \"activity_label\": \"Roof shingle removal\", \"ctx_a\": \"A man is sitting on a roof.\", \"ctx_b\": \"he\", \"ctx\": \"A man is sitting on a roof. he\", \"split\": \"val\", \"split_type\": \"indomain\", \"label\": 3, \"endings\": [\"is using wrap to wrap a pair of skis.\", \"is ripping level tiles off.\", \"is holding a rubik's cube.\", \"starts pulling up roofing on a roof.\"], \"source_id\": \"activitynet~v_-JhWjGDPHMY\"}\n",
    "\n",
    "ind: dataset ID\n",
    "activity_label: The ActivityNet or WikiHow label for this example\n",
    "context: There are two formats. The full context is in ctx. When the context ends in an (incomplete) noun phrase, like for ActivityNet, this incomplete noun phrase is in ctx_b, and the context up until then is in ctx_a. This can be useful for models such as BERT that need the last sentence to be complete. However, it's never required. If ctx_b is nonempty, then ctx is the same thing as ctx_a, followed by a space, then ctx_b.\n",
    "endings: a list of 4 endings. The correct index is given by label (0,1,2, or 3)\n",
    "split: train, val, or test.\n",
    "split_type: indomain if the activity label is seen during training, else zeroshot\n",
    "source_id: Which video or WikiHow article this example came from\n",
    "\n",
    "gpt2 (124M)\n",
    "- eleuther harness reports acc 28.92%, acc_norm 31.14% (multiple choice style)\n",
    "- this script: 10042 acc: 0.2859 acc_norm: 0.2955 (completion style)\n",
    "\n",
    "gpt2-xl (1558M)\n",
    "- eleuther harness reports acc 40.04%, acc_norm 50.89% (multiple choice style)\n",
    "- this script: 10042 acc: 0.3842 acc_norm: 0.4893 (completion style)\n",
    "\n",
    "The validation set of HellaSwag has a total of 10,042 examples.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import tiktoken\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "from uq.acquisition_func import BeamScore\n",
    "from uq.generate_with_uq import _enable_test_time_dropout\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = \"cuda\" if \"cuda\" in device else \"cpu\"\n",
    "# -----------------------------------------------------------------------------\n",
    "DATA_CACHE_DIR = os.path.join(os.getcwd(), \"local/hellaswag\")\n",
    "\n",
    "def download_file(url: str, fname: str, chunk_size=1024):\n",
    "    \"\"\"Helper function to download a file from a given url\"\"\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get(\"content-length\", 0))\n",
    "    with open(fname, \"wb\") as file, tqdm(\n",
    "        desc=fname,\n",
    "        total=total,\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "hellaswags = {\n",
    "    \"train\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_train.jsonl\",\n",
    "    \"val\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_val.jsonl\",\n",
    "    \"test\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_test.jsonl\",\n",
    "}\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def download(split):\n",
    "    \"\"\"Downloads HellaSwag DATA_CACHE_DIR\"\"\"\n",
    "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "    data_url = hellaswags[split]\n",
    "    data_filename = os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\")\n",
    "    if not os.path.exists(data_filename):\n",
    "        print(f\"Downloading {data_url} to {data_filename}...\")\n",
    "        download_file(data_url, data_filename)\n",
    "\n",
    "def render_example(example):\n",
    "    \"\"\"\n",
    "    Given the example as a dictionary, render it as three torch tensors:\n",
    "    - tokens (the tokens of context + completion, of size 4xN, as there are always 4 candidates)\n",
    "    - mask (is 1 in the region of the candidate completion, where we evaluate likelihoods)\n",
    "    - label (the index of the correct completion, which we hope has the highest likelihood)\n",
    "    \"\"\"\n",
    "    ctx = example[\"ctx\"]\n",
    "    label = example[\"label\"]\n",
    "    endings = example[\"endings\"]\n",
    "\n",
    "    # data needed to reproduce this eval on the C size\n",
    "    data = {\n",
    "        \"label\": label,\n",
    "        \"ctx_tokens\": None,\n",
    "        \"ending_tokens\": [],\n",
    "    }\n",
    "\n",
    "    # gather up all the tokens\n",
    "    ctx_tokens = enc.encode(ctx)\n",
    "    data[\"ctx_tokens\"] = ctx_tokens\n",
    "    tok_rows = []\n",
    "    mask_rows = []\n",
    "    for end in endings:\n",
    "        end_tokens = enc.encode(\" \" + end) # note: prepending \" \" because GPT-2 tokenizer\n",
    "        tok_rows.append(ctx_tokens + end_tokens)\n",
    "        mask_rows.append([0]*len(ctx_tokens) + [1]*len(end_tokens))\n",
    "        data[\"ending_tokens\"].append(end_tokens)\n",
    "\n",
    "    # have to be careful during the collation because the number of tokens in each row can differ\n",
    "    max_len = max(len(row) for row in tok_rows)\n",
    "    tokens = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    mask = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    for i, (tok_row, mask_row) in enumerate(zip(tok_rows, mask_rows)):\n",
    "        tokens[i, :len(tok_row)] = torch.tensor(tok_row)\n",
    "        mask[i, :len(mask_row)] = torch.tensor(mask_row)\n",
    "\n",
    "    return data, tokens, mask, label\n",
    "\n",
    "def iterate_examples(split):\n",
    "    # there are 10,042 examples in total in val\n",
    "    download(split)\n",
    "    with open(os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\"), \"r\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            yield example\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model_type, device):\n",
    "\n",
    "    torch.set_float32_matmul_precision('high') # use tf32\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    model.to(device)\n",
    "    # model = torch.compile(model) # optionally torch compile the model\n",
    "\n",
    "    num_correct_norm = 0\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for example in iterate_examples(\"val\"):\n",
    "        data, tokens, mask, label = render_example(example)\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        # get the logits\n",
    "        logits = model(tokens).logits\n",
    "        # evaluate the autoregressive loss at all positions\n",
    "        shift_logits = (logits[..., :-1, :]).contiguous()\n",
    "        shift_tokens = (tokens[..., 1:]).contiguous()\n",
    "        flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "        flat_shift_tokens = shift_tokens.view(-1)\n",
    "        shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
    "        shift_losses = shift_losses.view(tokens.size(0), -1)\n",
    "        # now get the average loss just for the completion region (where mask == 1), in each row\n",
    "        shift_mask = (mask[..., 1:]).contiguous() # we must shift mask, so we start at the last prompt token\n",
    "        masked_shift_losses = shift_losses * shift_mask\n",
    "        # sum and divide by the number of 1s in the mask\n",
    "        sum_loss = masked_shift_losses.sum(dim=1)\n",
    "        avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "        # now we have a loss for each of the 4 completions\n",
    "        # the one with the lowest loss should be the most likely\n",
    "        pred = sum_loss.argmin().item()\n",
    "        pred_norm = avg_loss.argmin().item()\n",
    "\n",
    "        # accumulate stats\n",
    "        num_total += 1\n",
    "        num_correct += int(pred == label)\n",
    "        num_correct_norm += int(pred_norm == label)\n",
    "        print(f\"{num_total} acc_norm: {num_correct_norm}/{num_total}={num_correct_norm/num_total:.4f}\")\n",
    "\n",
    "        # debug: pretty print a few examples, and the losses in each case\n",
    "        if num_total < 10:\n",
    "            print(\"---\")\n",
    "            print(f\"Context:\\n {example['ctx']}\")\n",
    "            print(f\"Endings:\")\n",
    "            for i, end in enumerate(example[\"endings\"]):\n",
    "                print(f\"{i} (loss: {avg_loss[i].item():.4f}) {end}\")\n",
    "            print(f\"predicted: {pred_norm}, actual: {label}\")\n",
    "\n",
    "\n",
    "def get_most_likely_row(tokens, mask, logits):\n",
    "    # evaluate the autoregressive loss at all positions\n",
    "    shift_logits = (logits[..., :-1, :]).contiguous()\n",
    "    shift_tokens = (tokens[..., 1:]).contiguous()\n",
    "    flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "    flat_shift_tokens = shift_tokens.view(-1)\n",
    "    shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
    "    shift_losses = shift_losses.view(tokens.size(0), -1)\n",
    "    # now get the average loss just for the completion region (where mask == 1), in each row\n",
    "    shift_mask = (mask[..., 1:]).contiguous() # we must shift mask, so we start at the last prompt token\n",
    "    masked_shift_losses = shift_losses * shift_mask\n",
    "    # sum and divide by the number of 1s in the mask\n",
    "    sum_loss = masked_shift_losses.sum(dim=1)\n",
    "    avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "    # now we have a loss for each of the 4 completions\n",
    "    # the one with the lowest loss should be the most likely\n",
    "    pred_norm = avg_loss.argmin().item()\n",
    "\n",
    "    return pred_norm\n",
    "\n",
    "\n",
    "def get_uncertainty_of_selected_tokens(tokens, mask, logits):\n",
    "    logits = F.log_softmax(logits, dim=-1)\n",
    "    logits_of_selected_tokens = torch.gather(logits, -1, tokens.unsqueeze(-1)).squeeze(-1)\n",
    "    logits_of_selected_tokens[mask] = 0\n",
    "    # Find uncertainty for the most likely row\n",
    "    uncertainty = BeamScore()(tokens.unsqueeze(0), logits_of_selected_tokens.unsqueeze(0))\n",
    "    assert uncertainty.shape == (1,)\n",
    "    return uncertainty.item()\n",
    "\n",
    "def get_uncertainty_of_selected_tokens_mcdo(model, tokens, mask, num_mc_samples=10):\n",
    "    \"\"\"\n",
    "    Computes uncertainty using Monte Carlo dropout (MCdo).\n",
    "    \n",
    "    This function runs several stochastic forward passes with dropout enabled\n",
    "    so that the resulting log probabilities for the tokens in the completion region\n",
    "    will vary. The variance of these log probabilities is taken as our uncertainty measure.\n",
    "    \n",
    "    Args:\n",
    "      model: The language model to use.\n",
    "      tokens: A 1D torch.Tensor of token IDs (of shape (T,)) for one candidate completion.\n",
    "      mask: A 1D torch.Tensor of the same length as tokens, where 1 indicates a token that is \n",
    "            part of the completion (and 0 indicates context tokens that are ignored).\n",
    "      num_mc_samples: Number of MC dropout forward passes.\n",
    "    \n",
    "    Returns:\n",
    "      A scalar uncertainty value (a higher value indicates higher uncertainty).\n",
    "    \"\"\"\n",
    "    # Save the current training/eval mode and enable dropout.\n",
    "    _enable_test_time_dropout(model)\n",
    "    \n",
    "    mc_samples = []\n",
    "    # Our model expects a batch dimension, so add one.\n",
    "    tokens = tokens.unsqueeze(0)  # shape: (1, T)\n",
    "    \n",
    "    for _ in range(num_mc_samples):\n",
    "        with torch.no_grad():\n",
    "            # Perform a forward pass (dropout is active because model is in training mode)\n",
    "            logits, _ = model(tokens)  # logits has shape: (1, T, vocab_size)\n",
    "        logits = logits.squeeze(0)  # Remove the batch dimension, now (T, vocab_size)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)  # (T, vocab_size)\n",
    "        # Gather the log-probabilities for the provided token sequence.\n",
    "        selected_log_probs = torch.gather(log_probs, -1, tokens[0].unsqueeze(-1)).squeeze(-1)  # (T,)\n",
    "        # Only consider tokens in the completion region (mask==1)\n",
    "        selected_log_probs = selected_log_probs[mask.bool()]\n",
    "        mc_samples.append(selected_log_probs)\n",
    "        \n",
    "    mc_samples = torch.stack(mc_samples, dim=0)  # Shape: (num_mc_samples, L)\n",
    "    # Compute the variance across the MC samples for each token in the completion region.\n",
    "    token_variances = torch.var(mc_samples, dim=0)\n",
    "    # Average the per-token variance to yield a single uncertainty measure.\n",
    "    uncertainty = token_variances.mean()\n",
    "    \n",
    "    return uncertainty.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_hellaswag(model):\n",
    "    num_correct_norm = 0\n",
    "    num_total = 0\n",
    "\n",
    "    correct_list = []\n",
    "    uncertainty_list = []\n",
    "    pbar = tqdm(total=10042, desc=\"Evaluating HellaSwag\")    \n",
    "    for i, example in enumerate(iterate_examples(\"val\")):\n",
    "        # Render the example into tokens, mask, and label.\n",
    "        _, tokens, mask, label = render_example(example)\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # Obtain a forward pass from the model.\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "                logits, loss = model(tokens)\n",
    "            # Use the existing routine to choose the candidate with the lowest (average) loss.\n",
    "            pred_norm = get_most_likely_row(tokens, mask, logits)\n",
    "            # Compute uncertainty via MC dropout for the selected candidate row.\n",
    "            uncertainty = get_uncertainty_of_selected_tokens_mcdo(model, tokens[pred_norm], mask[pred_norm])\n",
    "        num_total += 1\n",
    "        num_correct_norm += int(pred_norm == label)\n",
    "\n",
    "        correct_list.append(int(pred_norm == label))\n",
    "        uncertainty_list.append(uncertainty)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'acc': f'{num_correct_norm/num_total:.4f}'})\n",
    "    \n",
    "    pbar.close()\n",
    "    acc_norm = num_correct_norm / num_total\n",
    "    print(f\"HellaSwag accuracy: {num_correct_norm}/{num_total}={acc_norm:.4f}\")\n",
    "\n",
    "    # Save the correctness and uncertainty lists to files for later analysis.\n",
    "    with open(\"local/correct_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(correct_list, f)\n",
    "    with open(\"local/uncertainty_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(uncertainty_list, f)\n",
    "\n",
    "evaluate_hellaswag(gpt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAHWCAYAAAChaFm7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAiA5JREFUeJzs3XlcVOX+B/DPLMyw7zsiq4o7Ckq4Lyj6s9LKUjMX2m5pZhcro3LLjKwsS71aXlPTSsvUvGmaouSGG4orIq4osoqAgGwzz+8PZHIElGE7oJ/36zWv25zznOd8z5HL+fKcZ5EJIQSIiIiIGphc6gCIiIjo0cQkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiBqFmTNnQiaTSR0GETUgJiFETciKFSsgk8l0H6VSCTc3N4wfPx7Jyck1qvPMmTOYOXMmLl++XLfBVqKgoAAzZ85EdHR0vZ/LUIWFhfjqq68QFBQEKysrGBsbo2XLlnjjjTdw7tw5qcMjeijJuHYMUdOxYsUKhIWF4aOPPoKXlxcKCwtx4MABrFixAp6enjh16hSMjY0NqnPdunV49tlnsWvXLvTp06d+Ar8jMzMTDg4OmDFjBmbOnKm3r7S0FKWlpQbHX1dxDRo0CLGxsXj88ccREhICc3NzJCQkYM2aNUhNTUVxcXGDx0X0sFNKHQARGW7w4MEIDAwEALz88suwt7fH3LlzsWnTJjz33HMSR1czSqUSSqU0v5LGjx+PY8eOYd26dXjmmWf09s2ePRsffPBBnZyntLQUWq0WKpWqTuojaur4OoboIdCzZ08AwIULF/S2nz17FsOHD4etrS2MjY0RGBiITZs26favWLECzz77LACgb9++utc8d78u+fPPP9GzZ0+YmZnBwsICQ4YMwenTp/XOM378eJibmyM5ORnDhg2Dubk5HBwc8Pbbb0Oj0QAALl++DAcHBwDArFmzdOcqbxGprE9IaWkpZs+eDR8fH6jVanh6euL9999HUVGRXjlPT088/vjj2Lt3L7p27QpjY2N4e3vjhx9+eOC9O3jwIDZv3oyXXnqpQgICAGq1Gl988YXue58+fSptMRo/fjw8PT113y9fvgyZTIYvvvgC8+fP113DsWPHoFQqMWvWrAp1JCQkQCaTYeHChbpt2dnZeOutt+Du7g61Wg1fX1/MnTsXWq32gddG1NgxCSF6CJT357CxsdFtO336NB577DHEx8fjvffew7x582BmZoZhw4Zhw4YNAIBevXrhzTffBAC8//77WLVqFVatWoXWrVsDAFatWoUhQ4bA3Nwcc+fOxbRp03DmzBn06NGjQh8SjUaD0NBQ2NnZ4YsvvkDv3r0xb948fPfddwAABwcHLF68GADw1FNP6c719NNPV3ldL7/8MqZPn47OnTvjq6++Qu/evREZGYmRI0dWKHv+/HkMHz4cAwYMwLx582BjY4Px48dXSJjuVZ6UjRkz5r7lamr58uVYsGABXn31VcybNw8uLi7o3bs3fvnllwpl165dC4VCoUsMCwoK0Lt3b6xevRpjx47FN998g+7duyMiIgLh4eH1Ei9RgxJE1GQsX75cABA7duwQGRkZ4urVq2LdunXCwcFBqNVqcfXqVV3Z/v37i/bt24vCwkLdNq1WK7p16yZatGih2/brr78KAGLXrl1657p165awtrYWr7zyit721NRUYWVlpbd93LhxAoD46KOP9Mp26tRJBAQE6L5nZGQIAGLGjBkVrm3GjBni7l9JcXFxAoB4+eWX9cq9/fbbAoDYuXOnbpuHh4cAIHbv3q3blp6eLtRqtZgyZUqFc93tqaeeEgDEzZs371uuXO/evUXv3r0rbB83bpzw8PDQfb906ZIAICwtLUV6erpe2W+//VYAECdPntTb3qZNG9GvXz/d99mzZwszMzNx7tw5vXLvvfeeUCgUIikpqVoxEzVWbAkhaoJCQkLg4OAAd3d3DB8+HGZmZti0aROaNWsGAMjKysLOnTvx3HPP4datW8jMzERmZiZu3LiB0NBQJCYmPnA0zfbt25GdnY1Ro0bpjs/MzIRCoUBQUBB27dpV4ZjXXntN73vPnj1x8eLFGl3jli1bAKDCX/xTpkwBAGzevFlve5s2bXSvpYCylpdWrVo98Py5ubkAAAsLixrF+SDPPPOM7jVUuaeffhpKpRJr167VbTt16hTOnDmDESNG6Lb9+uuv6NmzJ2xsbPT+DUJCQqDRaLB79+56iZmoobBjKlETtGjRIrRs2RI5OTn4/vvvsXv3bqjVat3+8+fPQwiBadOmYdq0aZXWkZ6eDjc3tyrPkZiYCADo169fpfstLS31vhsbG1d42NrY2ODmzZvVuqZ7XblyBXK5HL6+vnrbnZ2dYW1tjStXruhtb968eYU6qnP+8uu4desWrK2taxTr/Xh5eVXYZm9vj/79++OXX37B7NmzAZS9ilEqlXqvpxITE3HixIkK97Vcenp6ncdL1JCYhBA1QV27dtWNjhk2bBh69OiB559/HgkJCTA3N9d1Wnz77bcRGhpaaR33PtzvVV7HqlWr4OzsXGH/vSNZFAqFwddRHdWdwKyq84sHzELg5+cHADh58qReS8r94qmszvIOuPcyMTGpdPvIkSMRFhaGuLg4+Pv745dffkH//v1hb2+vK6PVajFgwAC8++67ldbRsmXLB8ZL1JgxCSFq4hQKBSIjI9G3b18sXLgQ7733Hry9vQEARkZGCAkJue/xVT3kfXx8AACOjo4PrKO6DJkR1cPDA1qtFomJibqOsgCQlpaG7OxseHh41ElMTzzxBCIjI7F69epqJSE2NjaVvuK5t2XmQYYNG4Z//etfulcy586dQ0REhF4ZHx8f5OXl1dn9J2ps2CeE6CHQp08fdO3aFfPnz0dhYSEcHR3Rp08ffPvtt0hJSalQPiMjQ/ffZmZmAMqGgt4tNDQUlpaW+OSTT1BSUnLfOqrL1NS00nNV5v/+7/8AAPPnz9fb/uWXXwIAhgwZYvD5KxMcHIxBgwbhv//9LzZu3Fhhf3FxMd5++23ddx8fH5w9e1bv+o8fP459+/YZdF5ra2uEhobil19+wZo1a6BSqTBs2DC9Ms899xxiYmKwbdu2CsdnZ2ejtLTUoHMSNTZsCSF6SLzzzjt49tlnsWLFCrz22mtYtGgRevTogfbt2+OVV16Bt7c30tLSEBMTg2vXruH48eMAAH9/fygUCsydOxc5OTlQq9Xo168fHB0dsXjxYowZMwadO3fGyJEj4eDggKSkJGzevBndu3fXm8+iOkxMTNCmTRusXbsWLVu2hK2tLdq1a4d27dpVKNuxY0eMGzcO3333HbKzs9G7d28cOnQIK1euxLBhw9C3b986uW8A8MMPP2DgwIF4+umn8cQTT6B///4wMzNDYmIi1qxZg5SUFN1cIS+++CK+/PJLhIaG4qWXXkJ6ejqWLFmCtm3b6jq5VteIESPwwgsv4D//+Q9CQ0Mr9El55513sGnTJjz++OMYP348AgICkJ+fj5MnT2LdunW4fPmy3usboiZH4tE5RGSA8iG6hw8frrBPo9EIHx8f4ePjI0pLS4UQQly4cEGMHTtWODs7CyMjI+Hm5iYef/xxsW7dOr1jly5dKry9vYVCoagwXHfXrl0iNDRUWFlZCWNjY+Hj4yPGjx8vjhw5oiszbtw4YWZmViGme4fdCiHE/v37RUBAgFCpVHrDdSsrW1JSImbNmiW8vLyEkZGRcHd3FxEREXrDjoUoG6I7ZMiQCuevajhtZQoKCsQXX3whunTpIszNzYVKpRItWrQQkyZNEufPn9cru3r1auHt7S1UKpXw9/cX27Ztq3KI7ueff17lOXNzc4WJiYkAIFavXl1pmVu3bomIiAjh6+srVCqVsLe3F926dRNffPGFKC4urta1ETVWXDuGiIiIJME+IURERCQJJiFEREQkCSYhREREJIlGkYQsWrQInp6eMDY2RlBQEA4dOlRl2fXr1yMwMBDW1tYwMzODv78/Vq1apVemfHXOez+ff/55fV8KERERVZPkScjatWsRHh6OGTNm4OjRo+jYsSNCQ0OrnI7Y1tYWH3zwAWJiYnDixAmEhYUhLCxMbxx9SkqK3uf777+HTCardJluIiIikobko2OCgoLQpUsX3XwDWq0W7u7umDRpEt57771q1dG5c2cMGTJEtwbDvYYNG4Zbt24hKiqqzuImIiKi2pF0srLi4mLExsbqTVUsl8sREhKCmJiYBx4vhMDOnTuRkJCAuXPnVlomLS0NmzdvxsqVK6usp6ioCEVFRbrvWq0WWVlZsLOzM2iaaSIiokedEAK3bt2Cq6sr5PL7v3CRNAnJzMyERqOBk5OT3nYnJyecPXu2yuNycnLg5uaGoqIiKBQK/Oc//8GAAQMqLbty5UpYWFjorUx5r8jISMyaNatmF0FEREQVXL16Fc2aNbtvmSY5bbuFhQXi4uKQl5eHqKgohIeHw9vbG3369KlQ9vvvv8fo0aNhbGxcZX0REREIDw/Xfc/JyUHz5s1x9erVCsuVExERUdVyc3Ph7u4OCwuLB5aVNAmxt7eHQqFAWlqa3va0tLRKlw4vJ5fLdcuQ+/v7Iz4+HpGRkRWSkD179iAhIUG3SmVV1Go11Gp1he2WlpZMQoiIiGqgOt0ZJB0do1KpEBAQoNdhVKvVIioqCsHBwdWuR6vV6vXpKLds2TIEBASgY8eOdRIvERER1R3JX8eEh4dj3LhxCAwM1C1Fnp+fj7CwMADA2LFj4ebmhsjISABl/TcCAwPh4+ODoqIibNmyBatWrcLixYv16s3NzcWvv/6KefPmNfg1ERER0YNJnoSMGDECGRkZmD59OlJTU+Hv74+tW7fqOqsmJSXp9a7Nz8/HhAkTcO3aNZiYmMDPzw+rV6/GiBEj9Opds2YNhBAYNWpUg14PERERVY/k84Q0Rrm5ubCyskJOTg77hFCTpNFoUFJSInUYRPQQUigUUCqVVfb5MOQZKnlLCBHVrby8PFy7dg38+4KI6oupqSlcXFygUqlqVQ+TEKKHiEajwbVr12BqagoHBwdOtkdEdUoIgeLiYmRkZODSpUto0aLFAyckux8mIUQPkZKSEggh4ODgABMTE6nDIaKHkImJCYyMjHDlyhUUFxffdx6uB5F8ATsiqntsASGi+lSb1g+9euqkFiIiIiIDMQkhIiIiSTAJISKqBplMho0bNzaaesgwy5Ytw8CBA6UOo1Y8PT0xf/78Oq93/PjxGDZsmO77yJEjG2yiTyYhRNQopKamYtKkSfD29oZarYa7uzueeOIJvWUdmpKZM2fC39+/wvaUlBQMHjy4QWKIjIyEQqHA559/3iDna6wKCwsxbdo0zJgxQ7etoKAAERER8PHxgbGxMRwcHNC7d2/8/vvvEkZaZsWKFbC2tpbs/B9++CHmzJmDnJycej8XkxAiktzly5cREBCAnTt34vPPP8fJkyexdetW9O3bFxMnTpQ6vDrl7Oxc6YKZ9eH777/Hu+++i++//75Bznc/xcXFkp173bp1sLS0RPfu3XXbXnvtNaxfvx4LFizA2bNnsXXrVgwfPhw3btyQLM7Gol27dvDx8cHq1avr/2SCKsjJyREARE5OjtShEBnk9u3b4syZM+L27dtCCCG0Wq3ILyqR5KPVaqsd9+DBg4Wbm5vIy8ursO/mzZtCCCEuXbokAIhjx47p7QMgdu3aJYQQYteuXQKA2Lp1q/D39xfGxsaib9++Ii0tTWzZskX4+fkJCwsLMWrUKJGfn6+rx8PDQ3z11Vd65+3YsaOYMWOG7jsAsWHDBt33d999V7Ro0UKYmJgILy8v8eGHH4ri4mIhhBDLly8XAPQ+y5cvr1BPcHCwePfdd/XOm56eLpRKpfj777+FEEIUFhaKKVOmCFdXV2Fqaiq6du2qu977iY6OFm5ubqK4uFi4urqKffv26e3XaDRi7ty5wsfHR6hUKuHu7i4+/vhj3f6rV6+KkSNHChsbG2FqaioCAgLEgQMHhBBCjBs3TgwdOlSvvsmTJ4vevXvrvvfu3VtMnDhRTJ48WdjZ2Yk+ffoIIYSYN2+eaNeunTA1NRXNmjUTr7/+urh165ZeXXv37hW9e/cWJiYmwtraWgwcOFBkZWWJlStXCltbW1FYWKhXfujQoeKFF16o8l4MGTJEvP3223rbrKysxIoVK+57Dz08PMTs2bPFmDFjhJmZmWjevLn4/fffRXp6unjyySeFmZmZaN++vTh8+LDecevWrRNt2rQRKpVKeHh4iC+++EJvf1ZWlhgzZoywtrYWJiYmYtCgQeLcuXNCiH9+hu/+lP8cenh4iDlz5oiwsDBhbm4u3N3dxbfffqtXd1JSknj22WeFlZWVsLGxEU8++aS4dOmSbn9paan497//LaysrIStra145513xNixYyv8e86aNUv06NGjyntz7++auxnyDOU8IUQPsdslGrSZvk2Sc5/5KBSmqgf/isnKysLWrVsxZ84cmJmZVdhfk2bpmTNnYuHChTA1NcVzzz2H5557Dmq1Gj/99BPy8vLw1FNPYcGCBZg6darBdZezsLDAihUr4OrqipMnT+KVV16BhYUF3n33XYwYMQKnTp3C1q1bsWPHDgCAlZVVhTpGjx6Nzz77DJ9++qluWPXatWvh6uqKnj17AgDeeOMNnDlzBmvWrIGrqys2bNiAQYMG4eTJk2jRokWV8S1btgyjRo2CkZERRo0ahWXLlqFbt266/REREVi6dCm++uor9OjRAykpKTh79iyAsll3e/fuDTc3N2zatAnOzs44evQotFqtQfdo5cqVeP3117Fv3z7dNrlcjm+++QZeXl64ePEiJkyYgHfffRf/+c9/AABxcXHo378/XnzxRXz99ddQKpXYtWsXNBoNnn32Wbz55pvYtGkTnn32WQBAeno6Nm/ejL/++qvKOPbu3YsxY8bobXN2dsaWLVvw9NNPw8LCospjv/rqK3zyySeYNm0avvrqK4wZMwbdunXDiy++iM8//xxTp07F2LFjcfr0achkMsTGxuK5557DzJkzMWLECOzfvx8TJkyAnZ0dxo8fD6CsD0ZiYiI2bdoES0tLTJ06Ff/3f/+HM2fOoFu3bpg/fz6mT5+OhIQEAIC5ubkunnnz5mH27Nl4//33sW7dOrz++uvo3bs3WrVqhZKSEoSGhiI4OBh79uyBUqnExx9/jEGDBuHEiRNQqVSYN28eVqxYge+//x6tW7fGvHnzsGHDBvTr10/vurt27Yo5c+agqKioflvuHpimPILYEkJN1b1/neQXlQiPqX9I8skvKqlWzAcPHhQAxPr16+9bzpCWkB07dujKREZGCgDiwoULum3/+te/RGhoqO57TVpC7vX555+LgIAA3fcZM2aIjh07Vih3dz3lrR67d+/W7Q8ODhZTp04VQghx5coVoVAoRHJysl4d/fv3FxEREVXGkpOTI0xMTERcXJwQQohjx44Jc3NzXYtDbm6uUKvVYunSpZUe/+233woLCwtx48aNSvdXtyWkU6dOVcZY7tdffxV2dna676NGjRLdu3evsvzrr78uBg8erPs+b9484e3tXWXLW/nPyN33WAgh/v77b9GsWTNhZGQkAgMDxVtvvSX27t2rV8bDw0OvhSUlJUUAENOmTdNti4mJEQBESkqKEEKI559/XgwYMECvnnfeeUe0adNGCCHEuXPnBAC9lqnMzExhYmIifvnlFyFEWUualZVVhWu5Nx6tViscHR3F4sWLhRBCrFq1SrRq1UrvXhQVFQkTExOxbds2IYQQLi4u4rPPPtPtLykpEc2aNavw73n8+HEBQFy+fLlCHEKwJYSIqsHESIEzH4VKdu7qEPWwxk2HDh10/+3k5ARTU1N4e3vrbTt06FCtzrF27Vp88803uHDhAvLy8lBaWmrwgpcODg4YOHAgfvzxR/Ts2ROXLl1CTEwMvv32WwDAyZMnodFo0LJlS73jioqKYGdnV2W9P//8M3x8fNCxY0cAgL+/Pzw8PLB27Vq89NJLiI+PR1FREfr371/p8XFxcejUqRNsbW0Nup57BQQEVNi2Y8cOREZG4uzZs8jNzUVpaSkKCwtRUFAAU1NTxMXF6Vo5KvPKK6+gS5cuSE5OhpubG1asWIHx48dXOUHf7du3AaDCrJ69evXCxYsXceDAAezfvx9RUVH4+uuvMWvWLEybNk1X7t6fJQBo3759hW3p6elwdnZGfHw8hg4dqneu7t27Y/78+dBoNIiPj4dSqURQUJBuv52dHVq1aoX4+Pgqr7uyeGQyGZydnZGeng4AOH78OM6fP1+hZaewsBAXLlxATk4OUlJS9M6tVCoRGBhY4f+H5TMuFxQUPDCm2mASQvQQk8lk1XolIqUWLVpAJpPpXgVUpXyGxrt/WVa1UrCRkZHuv2Uymd738m13v1qQy+UVfgnfbxXimJgYjB49GrNmzUJoaCisrKywZs2aGg1rHD16NN58800sWLAAP/30E9q3b697yOXl5UGhUCA2NhYKhX5Sd3cT/b2WLVuG06dPQ6n8599eq9Xi+++/x0svvfTAKf0ftL+69+ve12uXL1/G448/jtdffx1z5syBra0t9u7di5deegnFxcUwNTV94Lk7deqEjh074ocffsDAgQNx+vRpbN68ucrydnZ2kMlkuHnzZoV9RkZG6NmzJ3r27ImpU6fi448/xkcffYSpU6fqFma792epqm2Gvqqqqfv9LOfl5SEgIAA//vhjheMcHBwMOk9WVlaNjjMUR8cQkaRsbW0RGhqKRYsWIT8/v8L+7OxsAP/8MkxJSdHti4uLq5MYHBwc9OrNzc3FpUuXqiy/f/9+eHh44IMPPkBgYCBatGiBK1eu6JVRqVTQaDQPPPfQoUNRWFiIrVu34qeffsLo0aN1+zp16gSNRoP09HT4+vrqfZydnSut7+TJkzhy5Aiio6MRFxen+0RHRyMmJgZnz55FixYtYGJiUuXw5w4dOiAuLk73ILrXvfcLqN6/RWxsLLRaLebNm4fHHnsMLVu2xPXr1yuc+0HDsl9++WWsWLECy5cvR0hICNzd3assq1Kp0KZNG5w5c+aB8bVp00bXMlNTrVu31usDAwD79u1Dy5YtoVAo0Lp1a5SWluLgwYO6/Tdu3EBCQgLatGmji7k6Pzv36ty5MxITE+Ho6Fjh58XKygpWVlZwcXHRO3dpaSliY2Mr1HXq1Ck0a9YM9vb2BsdhCCYhRCS5RYsWQaPRoGvXrvjtt9+QmJiI+Ph4fPPNNwgODgZQ9tf5Y489hk8//RTx8fH4+++/8eGHH9bJ+fv164dVq1Zhz549OHnyJMaNG1eh5eFuLVq0QFJSEtasWYMLFy7gm2++wYYNG/TKeHp64tKlS4iLi0NmZiaKiooqrcvMzAzDhg3DtGnTEB8fj1GjRun2tWzZEqNHj8bYsWOxfv16XLp0CYcOHUJkZGSVf/0vW7YMXbt2Ra9evdCuXTvdp1evXujSpQuWLVsGY2NjTJ06Fe+++y5++OEHXLhwAQcOHMCyZcsAAKNGjYKzszOGDRuGffv24eLFi/jtt98QExOju19HjhzBDz/8gMTERMyYMQOnTp164H329fVFSUkJFixYgIsXL2LVqlVYsmSJXpmIiAgcPnwYEyZMwIkTJ3D27FksXrwYmZmZujLPP/88rl27hqVLl+LFF1984HlDQ0Oxd+9evW19+vTBt99+i9jYWFy+fBlbtmzB+++/j759+xr8Wu1uU6ZMQVRUFGbPno1z585h5cqVWLhwId5++20AZT87Q4cOxSuvvIK9e/fi+PHjeOGFF+Dm5qZ7jePp6Ym8vDxERUUhMzOz2q9ERo8eDXt7ewwdOhR79uzBpUuXEB0djTfffBPXrl0DAEyePBmffvopNm7ciLNnz2LChAm6RP9ue/bsaZjJ3R7Ya+QRxI6p1FTdr7NYY3f9+nUxceJE4eHhIVQqlXBzcxNPPvmk3nDUM2fOiODgYGFiYiL8/f3FX3/9VWnH1PJhvUJU3snv3k6jOTk5YsSIEcLS0lK4u7uLFStWPLBj6jvvvCPs7OyEubm5GDFihPjqq6/0zlNYWCieeeYZYW1tXeUQ3XJbtmwRAESvXr0q3Jfi4mIxffp04enpKYyMjISLi4t46qmnxIkTJyqULSoqEnZ2dnodD+82d+5c4ejoKIqLi4VGoxEff/yx8PDwEEZGRqJ58+bik08+0ZW9fPmyeOaZZ4SlpaUwNTUVgYGB4uDBg7r906dPF05OTsLKykr8+9//Fm+88UaFjqmTJ0+uEMOXX34pXFxchImJiQgNDRU//PBDhX+z6Oho0a1bN6FWq4W1tbUIDQ3V2y+EEGPGjKl0uG5lTp8+LUxMTER2drZu2yeffCKCg4OFra2tMDY2Ft7e3uLNN98UmZmZujKVdVi+99+vsg7T5UN0y+/r559/rldH+RBdKysr3X0oH6Jb7rXXXhN2dnYVhug+qAN1SkqKGDt2rLC3txdqtVp4e3uLV155Rfc8KykpEZMnTxaWlpbC2tpahIeHVxiie/v2bWFlZSViYmKqvKd11TFVJkQ99Apr4nJzc2FlZYWcnJxaZcREDa2wsBCXLl2Cl5dXrZbXJmrs+vfvj7Zt2+Kbb76pVvlnn30WnTt3RkRERD1H1vQtXrwYGzZsuO+w5/v9rjHkGcrXMURE1GTcvHkTGzZsQHR0tEGz6X7++ef37cxL/zAyMsKCBQsa5FyNu9s8ERHRXTp16oSbN29i7ty5aNWqVbWP8/T0xKRJk+oxsofHyy+/3GDnYhJCRERNxuXLl6UOgeoQX8cQERGRJJiEED2E2N+ciOpTXf2OYRJC9BApn9tCymXTiejhVz53yb0zuBqKfUKIHiJKpRKmpqbIyMiAkZGRbqpzIqK6IIRAQUEB0tPTYW1tfd9J/aqDSQjRQ0Qmk8HFxQWXLl2qMI04EVFdsba2rnLpAEMwCSF6yKhUKrRo0YKvZIioXhgZGdW6BaQckxCih5BcLueMqUTU6PGFMREREUmCSQgRERFJgkkIERERSYJJCBEREUlC8iRk0aJF8PT0hLGxMYKCgnDo0KEqy65fvx6BgYGwtraGmZkZ/P39sWrVqgrl4uPj8eSTT8LKygpmZmbo0qULkpKS6vMyiIiIyECSJiFr165FeHg4ZsyYgaNHj6Jjx44IDQ1Fenp6peVtbW3xwQcfICYmBidOnEBYWBjCwsKwbds2XZkLFy6gR48e8PPzQ3R0NE6cOIFp06ZxpAAREVEjIxMSLjIRFBSELl26YOHChQAArVYLd3d3TJo0Ce+991616ujcuTOGDBmC2bNnAwBGjhwJIyOjSltIqlJUVISioiLd99zcXLi7uyMnJweWlpYGXBEREdGjLTc3F1ZWVtV6hkrWElJcXIzY2FiEhIT8E4xcjpCQEMTExDzweCEEoqKikJCQgF69egEoS2I2b96Mli1bIjQ0FI6OjggKCsLGjRvvW1dkZCSsrKx0H3d391pdGxERET2YZElIZmYmNBoNnJyc9LY7OTkhNTW1yuNycnJgbm4OlUqFIUOGYMGCBRgwYAAAID09HXl5efj0008xaNAg/PXXX3jqqafw9NNP4++//66yzoiICOTk5Og+V69erZuLJCIioio1uRlTLSwsEBcXh7y8PERFRSE8PBze3t7o06cPtFotAGDo0KH497//DQDw9/fH/v37sWTJEvTu3bvSOtVqNdRqdYNdAxEREUmYhNjb20OhUCAtLU1ve1pa2n0XxZHL5fD19QVQlmDEx8cjMjISffr0gb29PZRKJdq0aaN3TOvWrbF37966vwgiIiKqMclex6hUKgQEBCAqKkq3TavVIioqCsHBwdWuR6vV6jqVqlQqdOnSBQkJCXplzp07Bw8Pj7oJnIiIiOqEpK9jwsPDMW7cOAQGBqJr166YP38+8vPzERYWBgAYO3Ys3NzcEBkZCaCsA2lgYCB8fHxQVFSELVu2YNWqVVi8eLGuznfeeQcjRoxAr1690LdvX2zduhX/+9//EB0dLcUlEhERURUkTUJGjBiBjIwMTJ8+HampqfD398fWrVt1nVWTkpIgl//TWJOfn48JEybg2rVrMDExgZ+fH1avXo0RI0boyjz11FNYsmQJIiMj8eabb6JVq1b47bff0KNHjwa/PiIiIqqapPOENFaGjHEmIiKifzSJeUKIiIjo0cYkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEk5CF1NasAqTmFUodBRERUJSYhD6Gluy+i52e70O3TKPxy+KrU4RAREVWKSchDJulGAT7bdhYAoBXA9E2nkJJzW+KoiIiIKmIS8pD5+XASSjQCPXztEehhg8ISLX6IuSJ1WERERBUwCXmICCGw+UQKAGBkV3e81MMLAPDrkWvQaIWUoREREVWglDoAqjuXMvORlFUAlVKOfn6OUMrlsDRWIjOvCHFXbyLAw1bqEImIiHTYEvIQOXL5JgCgYzMrmKqUUCnl6N3KEQCwIz5dytCIiIgqYBLyEDlyJQsAEOj5T4tHSOuyJGTXWSYhRETUuDAJeYgcS8oGAAQ0t9Ft6+ZjDwBISLuF7IJiKcIiIiKqFJOQh0RRqQaXMvMBAG3dLHXbHSzU8HYwgxD/vK4hIiJqDJiEPCQuZeajVCtgoVbC2dJYb1+QV9nrmcOXs6QIjYiIqFJMQh4S59LyAAAtnS0gk8n09nW9k4QcuMQkhIiIGg8mIQ+JxLRbAICWTuYV9gXeGZp75noOiko1DRoXERFRVZiEPCQSUsuTEIsK+5rZmMDG1AglGoGzKbcaOjQiIqJKMQl5SFy+UdYp1duhYkuITCZDh2bWAIAT17IbMCoiIqKqNYokZNGiRfD09ISxsTGCgoJw6NChKsuuX78egYGBsLa2hpmZGfz9/bFq1Sq9MuPHj4dMJtP7DBo0qL4vQzJCCFzNKlukrrmtaaVlOrpbAwDiruY0VFhERET3Jfm07WvXrkV4eDiWLFmCoKAgzJ8/H6GhoUhISICjo2OF8ra2tvjggw/g5+cHlUqFP/74A2FhYXB0dERoaKiu3KBBg7B8+XLdd7Va3SDXI4XMvGLcLtFAJgPcrE0qLdOxmRUAtoQQEVHjIXlLyJdffolXXnkFYWFhaNOmDZYsWQJTU1N8//33lZbv06cPnnrqKbRu3Ro+Pj6YPHkyOnTogL179+qVU6vVcHZ21n1sbGwqre9hcPVmAQDAxdIYKmXl/6Tlr2POZ+Qhr6i0oUIjIiKqkqRJSHFxMWJjYxESEqLbJpfLERISgpiYmAceL4RAVFQUEhIS0KtXL7190dHRcHR0RKtWrfD666/jxo0bVdZTVFSE3NxcvU9TcjWrLAlpVsWrGKBs0jJXK2MIAZxK5isZIiKSnqRJSGZmJjQaDZycnPS2Ozk5ITU1tcrjcnJyYG5uDpVKhSFDhmDBggUYMGCAbv+gQYPwww8/ICoqCnPnzsXff/+NwYMHQ6OpfHhqZGQkrKysdB93d/e6ucAGUp6EVNUfpFx5v5DjV7PrOSIiIqIHk7xPSE1YWFggLi4OeXl5iIqKQnh4OLy9vdGnTx8AwMiRI3Vl27dvjw4dOsDHxwfR0dHo379/hfoiIiIQHh6u+56bm9ukEpGkO0mIu839k5AOzazx56lUnGBLCBERNQKSJiH29vZQKBRIS0vT256WlgZnZ+cqj5PL5fD19QUA+Pv7Iz4+HpGRkbok5F7e3t6wt7fH+fPnK01C1Gp1k+64Wj4yxt228k6p5Trc6Zx68hqTECIikp6kr2NUKhUCAgIQFRWl26bVahEVFYXg4OBq16PValFUVFTl/mvXruHGjRtwcXGpVbyN1fWcsiSkqpEx5dq5liUhSVkFDbaibnpuIU4l5+ByZj6KS7UNck4iImoaJH8dEx4ejnHjxiEwMBBdu3bF/PnzkZ+fj7CwMADA2LFj4ebmhsjISABl/TcCAwPh4+ODoqIibNmyBatWrcLixYsBAHl5eZg1axaeeeYZODs748KFC3j33Xfh6+urN4T3YSGEQGpOIQDAxer+SYiVqRE87Uxx+UYBTlzLQa+WDvUSU6lGi1+OXMOyvRdxISNft91UpUAPX3uMCfZAD1/7CmvcPIpKNFrcLCiGrakKSoXkg9WIiBqU5EnIiBEjkJGRgenTpyM1NRX+/v7YunWrrrNqUlIS5PJ/fjnn5+djwoQJuHbtGkxMTODn54fVq1djxIgRAACFQoETJ05g5cqVyM7OhqurKwYOHIjZs2c36VcuVcm5XYKiOy0MjpYPvr4Ozaxx+UYBTibXTxKSlV+MCT/G4sDFssXy5DLAzlyNvMJSFBRr8NeZNPx1Jg1dPW3x0bC28HO2rPMYmoLCEg0W7jyPH2IuI7ewFFYmRni5hxde7+PDZISIHhkyIYSQOojGJjc3F1ZWVsjJyYGlZeN+SCak3kLo/N2wNjVC3PSBDyz/3z0X8fHmeIS2dcK3YwLrNJa8olKM/C4Gp5JzYaZSYMrAVngmoBmsTIyg1QqcScnFuthrWHv4Km6XaKCUy/B2aCu82tMbcvmj0yqSX1SKl1Ye1iVqdxvYxgmLRneGERMRImqiDHmG8jddE5eaW/YqxtnSuFrl27uVz5xa951T319/EqeSc2FnpsKGid3xYg8vWJkYAQDkchnauVlh5pNtsWNKbwxs44RSrcCnf57FuOWHcCOv6j49DxOtVuDNn4/hwMUsmKuVWPR8ZyTOGYx5z3aESinHX2fSMGdzvNRhEhE1CCYhTVzanf4gTtVMQtq5WUEmA1JyCpF+q7DO4th2OhWbjl+HQi7Dd2MDK13Nt5ybtQm+HROAT59uD2MjOfYkZuLJhftw5nrTmiSuJr7dfRFRZ9OhUsqx6qWuGNLBBUYKOZ4JaIYFozoBAFbsv4xdCekSR0pEVP+YhDRx5S0hTtXoDwIAZmolfO+stFtXM6eWarT4ZEvZX++v9vJGgMeDp8iXyWQY2bU5Nr3RA172ZkjOvo1nFu/HnydT6iSmxuhSZj6+2n4OADDrybbo1Fz/PoW2dcZLPbwAAB9uOIWCYk6vT0QPNyYhTVyaga9jAKB9s7p9JbP+WDKu3CiAnZkKb/T1NejYlk4W2DihO3q2sMftEg1e//Eovtt9oU7iakyEEJj++ykUa7To1dIBI7tUPhle+ICWcLM2QXL2bXy3+2IDR0lE1LCYhDRx5UmIk1X1k5AOddgvRAiBb/8uSxr+1dsbZmrDB1xZmRph+fgueLF7WSvAJ1vOYuHOxFrH1phsP5OGPYmZUCnl+OjJtlUOTzZTKxHxf34AgKW7LyLzEekrQ0SPJiYhTZyhHVMBoMOdNWROXMtBbQdHHbqUhQsZ+TBVKTCqa/Ma16NUyDH9iTaYMqAlAOCLv87hx4NXahVbY6HVCny1oyypermHFzztze5b/v/auaC9mxXyi8uG8RIRPayYhDRxqTllfylXt2MqALRxsYRCLkNmXpEuiampnw8lAQCe7OgKC2OjWtUFAJP6t8BbIS0AADN+P40DF6te/bip+OtMKuJTcmGhVuLVXt4PLC+XyzB1UFlryI8Hr+DazYL6DpGISBJMQpqwEo0WN/INT0KMjRS60SvHr9b8lUxBcSm2ni5b7XhkLVpB7jW5fws82dEVpVqBf6+NQ25hSZ3V3dC0WoGvtpe1goR194S1qapax/VoYY9uPnYo0Qh8E/VwvZoiIirHJKQJy7hVBCEApVwGO7PqPdzKlfcLOZmcXePzRydkoLBEC3dbE3S809m1LshkMnz6THt42JkiJacQs/93ps7qbmh/nkpFQtotWBgr8VKPB7eC3O3t0FYAgN+OJuNiRl59hEdEJCkmIU3YjbyyRejszFUGzzjawb32nVP/PFXWCjK4nUudrwNjqlLii2c7QiYDfo29htgrFWcXbey0WoGvo8qG5L7Y3QtWpoa9rurc3Ab9/RyhuatPCRHRw4RJSAMp0Whr3Qn0XuUjJ+zNDV8Tp4ObNQDgZHLNOqcWlmiwMz4NADConbPBx1dHF09bPBdQNpT1oz/iodXW7woDdf3vs/lkCs6l5cHCWIkX78z/YajwgWUddf93/DriUx7+ydyI6NEi+QJ2j4pP/zxbNlnVCH/dVOa1VZ6E2NUgCWnlbAGVQo7sghJczbqN5namBh1/8FIW8os1cLJUw7+ZtcHnr64poS3xx4nrOH41G5uOX8ewTm51Um9uYQn+d/w69p3PRHzKLWTeKsKtolIo5TKYqZXwsjdDF08bPN7BFR3vjCYyhEYr8HVU+YgY7xr/m7d1tcKQDi7YfCIF8/46h/+Oq9v1foiIpMSWkAaQmVeEHw9ewc6z6Zi/41wd1lv2Osbe3LD+IACgUsrR2qWsc+qJGvQL2XMuAwDQu6VDvS4+52hhjAl3JkD7OioRpRptrerTaAX+u+ciukXuxAcbTmHLyVRcyszHraKy2UlLtQI5t0sQdzUbS/dcwtBF+zBm2UGcTzesT8YfJ67jfHoerEyMENbDs1Yx/zukJeQyYEd8GuKuZteqLiKixoRJSAOwN1fjy+f8AQCbT6TUWbP/jVq8jgH+mTn1ZA36hew9nwkA6NHCoUbnNsT4bp6wNVPhUmY+fo+7XuN68otK8coPR/Dx5njkFZXC19Ecbw9siR9fDsLOKb1x+IMQHIjoj61v9cTXI/3xZEdXGClk2JOYiccX7MEvR65W6zylGi2+vtOH45WeXrCs5dBlX0dzPN25GQBg3l8JtaqLiKgxYRLSQPq3doSRQob0W0W4dvN2ndT5T58Qw1tCgH/6hRy/lm3Qcem3CnE29RYAoLuPXY3ObQizu+bXWLCzZq0hRaUavLTyMHaeTYdaKUfk0+3x11u98Ea/Fujuaw9vB3M4WKjhbGUMP2dLDPV3wzejOmHnlD7o2cIehSVavLvuBL7afu6BSeS62Gu4mJkPa1MjjOvmWZNLrmBy/xa6hOhhmDuFiAhgEtJg1Mp/5uY4fb1u1my5kX9ndIxZ7VpCTiXnGtTpc9+dVpC2rpY16o9SE2Me84CtmQqXbxRgo4GtIUIITF13AgcuZsFcrcTPrz6GUV2bV+s1krutKVaGdcWkfv+8Enp/wyloqrhfOQUl+GxbWWvFG31962QCt/I4RtxZb+aLbQl13omWiEgKTEIaUBsXSwDQtSLUVsatOy0hFjVLBFo4msPYSI68olJczKx+n4c9iWVJSM8GeBVTzkytxL/utIZ8E5WIEgNaQ36NvYaNcdehlMuw5IUAdG7+4FV+7yaXyzBlYCvMeaod5LKyWWLf+Okoiko1FcrO+uM0svKL0cLRvM5aQcpN6tcCaqUcR67cxJaTqXVaNxGRFJiENKDyNUOSbtTNNNz/tITU7HWMUiFHhzsjW2Kv3KzWMUII7NUlIfY1Om9NjQn2gL25GklZBdXun3HlRj5mbToNoGy4a49axDw6yAOLnu8MlUKOP0+lImz5Ydy6azbXFfsuYf3RZMhlwCdPt4eRom7/7+VkaYx/9fYBAMz+4wzy7nSmJSJqqpiENKDmtmXDYK9k1T4J0WoFsu4kIQ41bAkBgK6etgCAQ5eql4Qkpuch/VYR1Eo5AjwMa1GoLVOVEhP7lj2EF0SdR2FJxZaIu5VotJi8Jg75xRp09bLFv3r51DqGwe1dsCKsC8xUCuy/cAMDvtyNeX8l4M2fj2HmnZldpwxshS537mtdm9DHBx52pkjNLcRX2+tupBURkRSYhDQgjztzcSTVQRKSfbtE1y/BtoYtIQAQ6FmWSByp5oyk5f1BunrZwthIUePz1tTzQc3hamWM1NxC/Hgw6b5lF+48j7ir2bAwVuKrEf5Q1NFQ4m6+9ljzajCa2ZggNbcQC3aex6bjZf1U3uzniwl9ap/sVMXYSIGPhrYDAKzYfxlnrnMCMyJqupiENCAP27LXMRm3inC7+P5/xT9I+cgYa1OjWjX7d/awgUwGXLlRgPRqrKi773zZyIxuPg37KqacWqnAm/3LVtldtOs8bt5pDbrXsaSbWLjrPADg42Ht4GZtUqdxtG9mhR3hvfHp0+3xbEAzhHX3xMaJ3RE+sFWdT2F/r94tHTCkvQs0WoEPN56s95lkiYjqC5OQBmRpooSpqqz1IK0aD/z70c2WWotWEACwNDaCn3NZh9kjD+gXUqrR4uCd4aHdfet/aG5VnglohpZO5sjKL8bszRUXt8stLEH4L8eh0Qo82dEVQ/3rZpbVexkbKTCya3N8/mxHzHiiLfxrMLNqTU17vA3MVAocTcqudv8YIqLGhklIA5LJZHCyNAYApNY6CSmfLbX2Q2S73nklc/jy/V/JnLqei1tFpbA0VqKta92tmmsoI4Ucnz7TATIZsP5oMjYeS9btKy7VYtJPx3ApMx8uVsaYfefVxcPG2coY4QPLVtmN/POsbuI6IqKmhElIA3O804m0ti0htZ0t9W6BdzpRPigJKe8PEuxjV2f9K2qqc3MbXd+Ld9Ydx3/3XMSRy1kYv/wQ/j6XARMjBZaODTR45dqmZFywB9q4WCLndgki/zwrdThERAZjEtLAyltC0nNr95drbWdLvVv5SI4z13ORU1BSZbn9F8qSEKn6g9xryoBWGOrvihKNwMeb4zF8SQz2X7gBU5UCS8YEoJ2bdK01DUGpkOPjp9pBJiubpfXQpep1LiYiaiyYhDQwZ6uyJKT2LSF35gipg5YQZytjtHA0h1b8sybMvQpLNDhyuazPiJT9Qe4ml8swf4Q/Zg9ti5ZO5rA3V2FwO2dseqM7erdsuInUpNS5uQ1GdmkOAPhw40mDJnEjIpKaUuoAHjW61zG36qYlxK4OWkKAshEXiel52H0uA0M6uFTYf+DiDRSVauFkqYaPg3mdnLMuyGQyjAn2xJhgT6lDkczUQa2w7XQqzqXlYfWBKwjr7iV1SERE1cKWkAZW/jqm9qNj6q5jKgD0utNy8Pe5jErXJYmKTwcA9PNzqvchqGQYa1MVpgxsCaBsbhTOpEpETQWTkAZW3hKSUUctIXXRJwQon3xMjtTcQiSk6a9tI4RAVHwaACCktWOdnI/q1nOB7vC2N8ON/GIs3X1R6nCIiKqFSUgDK399Utshlbo+ITVcQfdexkYKdL/T4XTLiRS9faev5+J6TiGMjeTo7ts4OqWSPiOFHG+Hlg3Z/e+ei7oklYioMWMS0sBs7yQNuYWlNe5EWFBcitt31k2pqz4hADC0U9mkXhvikvVeyaw/WjYPRz8/R0mmaqfqGdzOGR2bWSG/WIPv2BpCRE0Ak5AGZm1ihPIpNqqacvxByltBVAo5zNV117d4QGsnmKkUuJp1Wzfcs6hUg9/jypKQZzo3q7NzUd2TyWR4K6Ssb8iPB64gu6BmP19ERA2lUSQhixYtgqenJ4yNjREUFIRDhw5VWXb9+vUIDAyEtbU1zMzM4O/vj1WrVlVZ/rXXXoNMJsP8+fPrIXLDyeUy2JjeeSVTwySkfPVcO3NVnXYSNVEp8OSdKc4XRV8AUDb/xI38YjhZqnWdV6nx6tPKAW1cLJFfrMGK/ZelDoeI6L4kT0LWrl2L8PBwzJgxA0ePHkXHjh0RGhqK9PT0Ssvb2trigw8+QExMDE6cOIGwsDCEhYVh27ZtFcpu2LABBw4cgKura31fhkH+6RdSuySkNqvnVuX13j5QyGXYfS4D8/5KwBfbEgAA/+rlU6uF8qhhyGQyTOzrCwBYvu8yR8oQUaMm+VPlyy+/xCuvvIKwsDC0adMGS5YsgampKb7//vtKy/fp0wdPPfUUWrduDR8fH0yePBkdOnTA3r179colJydj0qRJ+PHHH2Fk1Lim7i5PHm7k16zz4I16TEKa25nqpkNfsPM8bhaUoI2LJV54zKPOz0X1Y1A7Z3jbmyHndgl+OnhF6nCIiKokaRJSXFyM2NhYhISE6LbJ5XKEhIQgJibmgccLIRAVFYWEhAT06tVLt12r1WLMmDF455130LZt2wfWU1RUhNzcXL1PfSof0ZJV49cxdbOCblXeCmmJSf180czGBCGtnbAirAtUSsnzVaomhVyG13qXJZLL913mLKpE1GhJ+mTJzMyERqOBk5OT3nYnJyekpqZWeVxOTg7Mzc2hUqkwZMgQLFiwAAMGDNDtnzt3LpRKJd58881qxREZGQkrKyvdx93dvWYXVE3lLRg1TULKX+PY1tHw3Hsp5DJMGdgKe6f2w3/HBcLxzgRr1HQ86e8Ke3MVUnIKse101f9fIiKSUpP889bCwgJxcXE4fPgw5syZg/DwcERHRwMAYmNj8fXXX2PFihXV7rQZERGBnJwc3efq1av1GP0/SUhmDfuE3LirYypRZYyNFHg+qOwV2vd7L0kcDRFR5SRNQuzt7aFQKJCWlqa3PS0tDc7OzlUeJ5fL4evrC39/f0yZMgXDhw9HZGQkAGDPnj1IT09H8+bNoVQqoVQqceXKFUyZMgWenp6V1qdWq2Fpaan3qU/lyUNWDfuE1GfHVHp4vPBYcxgpZDialI24q9lSh0NEVIGkSYhKpUJAQACioqJ027RaLaKiohAcHFzterRaLYqKyh7oY8aMwYkTJxAXF6f7uLq64p133ql0BI0UatsnRNcSwiSE7sPRwhhPdCwbGbZ8H1tDiKjxkXwV3fDwcIwbNw6BgYHo2rUr5s+fj/z8fISFhQEAxo4dCzc3N11LR2RkJAIDA+Hj44OioiJs2bIFq1atwuLFiwEAdnZ2sLPTX2reyMgIzs7OaNWqVcNeXBX+GR1Ty46pfB1DD/Bidy+sP5qMzSdSEDG4NZyt2L+HiBoPyZOQESNGICMjA9OnT0dqair8/f2xdetWXWfVpKQkyOX/NNjk5+djwoQJuHbtGkxMTODn54fVq1djxIgRUl2CwWo9T0g9d0ylh0c7Nyt09bTFoctZ+PlQEv49oKXUIRER6chEZeu2P+Jyc3NhZWWFnJyceukfkplXhMCPdwAAzs8ZDKUBk4AVlmjgN20rAOD4jIGwMmlcc6BQ4/N7XDImr4mDi5Ux9rzb16CfNyIiQxnyDOVvIwnYmKpQPnDnZkGJQceW9yMxUshgaSx5QxY1AYPaOcPG1AgpOYWITsiQOhwiIh0mIRJQyGWwvtOCYWjn1PJXOGWJTN2tG0MPL7VSgeEBZYsP/nwoSeJoiIj+wSREIjY1nLr9hq5TKvuDUPWN7NocALArIR3Xs29LHA0RURkmIRKxq+GsqVkcnks14ONgjse8baEVwNrD9TsZHxFRdTEJkUj5MN2bNUxCOFEZGWrUndaQtYevQqNlf3Qikh6TEImUD681dK6Q+lxBlx5ug9o5w8rECKm5hdh/IVPqcIiImIRIpcavY/L4OoZqRq1U4ImOLgCA9UeTJY6GiIhJiGRsajhrqq4lhLOlUg083blslMzWU6nIKyqVOBoietQxCZGIXY37hNwZHcPZUqkGOrlbw8veDLdLNNh6KlXqcIjoEcckRCK2NXwdo1u8ji0hVAMymQxPd3IDAKw/ek3iaIjoUcckRCI1XcTun3VjmIRQzQy7k4TEXLyBZM4ZQkQSYhIikfKWjJv5xaju8j1FpRrcuvMenx1TqabcbU0R5GULIYCNx9hBlYikwyREIjamZUlEqVYg93b1OgjezC9bZ0Yhl8HSmAvXUc09c6eD6vqj16qdBBMR1TUmIRIxNlLATKUAAGQVVO+VTPmU7TamKsjlXDeGam5we2cYG8lxISMfx6/lSB0OET2imIRIqHyYbVY114/hlO1UVyyMjRDa1hkA8FssO6gSkTSYhEhIN2tqXvVaQrI4MobqUPkrmU3Hr6OoVCNxNET0KGISIiFDZ03N5MgYqkPdfe3hbGmMnNsl2BmfLnU4RPQIYhIiIUOH6WbcKntt42DBicqo9hRymW647m+cM4SIJMAkREKGrqSbmcckhOrW8ICyJCQ6IUP380VE1FCYhEjI0FlTy1tC7M2ZhFDd8HW0QMdmVijVCmyKuy51OET0iGESIiG+jqHG4JmAsg6qv8ZyzhAialhMQiRkaMfUjPLXMWwJoTr0ZEdXqJVyxKfk4siVm1KHQ0SPECYhEjLkdYxGK3Tl2BJCdcnaVIWnO5f1DVm255LE0RDRo4RJiIQMSUJuFhRDoxWQyThEl+rei929AAB/nUnF1awCiaMhokcFkxAJlScTt0s0uF18/8miyvuD2JqqYKTgPxvVrRZOFujZwh5aASz++4LU4RDRI4JPMwmZq5VQ3Ukobjxg6vby4ZMcGUP1ZVK/FgCAtYev4lJmvsTRENGjgEmIhGQyWbVfyXBkDNW3rl626NvKARqtwKd/xksdDhE9ApiESKy6w3T/mSOE/UGo/kwd7AeFXIZtp9Ow5WSK1OEQ0UOOSYjEqjtrKmdLpYbg52yJCX18AAAfbDjJTqpEVK8MTkI8PT3x0UcfISkpqT7ieeTwdQw1NpP6tUB7NyvcLCjBiysO4wancyeiemJwEvLWW29h/fr18Pb2xoABA7BmzRoUFfGXVE1V93VMOpMQaiAqpRxLxwbCyVKNxPQ8PPttDFtEiKhe1CgJiYuLw6FDh9C6dWtMmjQJLi4ueOONN3D06NH6iPGhVt7H40F/babmFAIAnC1N6j0mImcrY/z0ymNwtTLGxYx8PL5gL3acSZM6LCJ6yNS4T0jnzp3xzTff4Pr165gxYwb++9//okuXLvD398f3339v0BoUixYtgqenJ4yNjREUFIRDhw5VWXb9+vUIDAyEtbU1zMzM4O/vj1WrVumVmTlzJvz8/GBmZgYbGxuEhITg4MGDNb3UeuVoYQwASM2tOgkRQiDlThLiYmXcIHER+TiYY93r3dCxmRVybpfg5R+OYPYfZ1BcqpU6NCJ6SNQ4CSkpKcEvv/yCJ598ElOmTEFgYCD++9//4plnnsH777+P0aNHV6uetWvXIjw8HDNmzMDRo0fRsWNHhIaGIj09vdLytra2+OCDDxATE4MTJ04gLCwMYWFh2LZtm65My5YtsXDhQpw8eRJ79+6Fp6cnBg4ciIyMjJpebr1xvpNUpN1JMiqTe7sUt0s0euWJGoKrtQl+fa2bbkbVZXsvYfiS/bhyg/OIEFHtyYSBy2YePXoUy5cvx88//wy5XI6xY8fi5Zdfhp+fn67MqVOn0KVLF9y+ffuB9QUFBaFLly5YuHAhAECr1cLd3R2TJk3Ce++9V62YOnfujCFDhmD27NmV7s/NzYWVlRV27NiB/v37P7C+8vI5OTmwtLSsVgw1dS7tFgZ+tRtWJkY4PmNgpWXOpuZi0Pw9sDE1wrHplZchqm/bz6Th7V+PI+d2CczVSnz6THs83sFV6rCIqJEx5BlqcEtIly5dkJiYiMWLFyM5ORlffPGFXgICAF5eXhg5cuQD6youLkZsbCxCQkL+CUguR0hICGJiYh54vBACUVFRSEhIQK9evao8x3fffQcrKyt07Nix0jJFRUXIzc3V+zQUJ8uylo2c2yUoLKl86vbyVzHOVuwPQtIZ0MYJf07uiUAPG+QVleKNn47hi20J0GoN+juGiEhHaegBFy9ehIeHx33LmJmZYfny5Q+sKzMzExqNBk5OTnrbnZyccPbs2SqPy8nJgZubG4qKiqBQKPCf//wHAwYM0Cvzxx9/YOTIkSgoKICLiwu2b98Oe3v7SuuLjIzErFmzHhhvfbA0VsLESIHbJRqk5hTC096sQplU9gehRsLV2gRrXn0Mn/+VgG//voiFu87j0o18zHu2I4yNFFKHR0RNjMEtIenp6ZV28jx48CCOHDlSJ0E9iIWFBeLi4nD48GHMmTMH4eHhiI6O1ivTt29fxMXFYf/+/Rg0aBCee+65KvuZREREICcnR/e5evVqA1xFGZlMpuvnkZpbeb+Qf1pCmISQ9JQKOSIGt8ZnwzvASCHD5hMpGPndAd1cNkRE1WVwEjJx4sRKH9LJycmYOHGiQXXZ29tDoVAgLU1/6F9aWhqcnZ2rPE4ul8PX1xf+/v6YMmUKhg8fjsjISL0yZmZm8PX1xWOPPYZly5ZBqVRi2bJlldanVqthaWmp92lITpZlc3+kVZGEpOaU9a1xsWQSQo3Hc4HuWPVSEKxNjRB3NRvDFu3DubRbUodFRE2IwUnImTNn0Llz5wrbO3XqhDNnzhhUl0qlQkBAAKKionTbtFotoqKiEBwcXO16tFrtAydMq04Zqbjc6euRWsUImevZbAmhxukxbztsmNAd3vZmSM6+jWcW78f+C5lSh0VETYTBSYhara7QcgEAKSkpUCoN7mKC8PBwLF26FCtXrkR8fDxef/115OfnIywsDAAwduxYRERE6MpHRkZi+/btuHjxIuLj4zFv3jysWrUKL7zwAgAgPz8f77//Pg4cOIArV64gNjYWL774IpKTk/Hss88aHF9DKO+cmlJFEpJ0Z7bK5ramDRYTUXV52Zvht9e7oYunDW4VlmLc94ew/ug1qcMioibA4Kxh4MCBiIiIwO+//w4rKysAQHZ2Nt5///0KnUOrY8SIEcjIyMD06dORmpoKf39/bN26VddZNSkpCXL5P7lSfn4+JkyYgGvXrsHExAR+fn5YvXo1RowYAQBQKBQ4e/YsVq5ciczMTNjZ2aFLly7Ys2cP2rZta3B8DaG8w2lKTsUhzSUaLZKzy7Y3t2MSQo2TjZkKq14Kwtu/HscfJ1IQ/stxXM26jTf7+0Imk0kdHhE1UgbPE5KcnIxevXrhxo0b6NSpEwAgLi4OTk5O2L59O9zd3esl0IbUkPOEAMCuhHSELT8MP2cLbH1Lf6hx0o0C9Pp8F1RKOc5+NAhyOX+hU+Ol1Qp8ti0BS/6+AAB4J7QVJvb1lTgqImpIhjxDDW4JcXNzw4kTJ/Djjz/i+PHjMDExQVhYGEaNGgUjI6MaB/0o87jzmiUpqwBCCL2/HK9klc1M2dzWlAkINXpyuQzvDfaDvbkKH2+Ox+fbEuBhZ8pJzYioUoZ34kDZyJNXX321rmN5ZDWzMYVcBhQUa5CRV6RbTwYArtwo6w/iwf4g1IS83NMbqTmF+O/eS4hYfxL+7tZoZsOfYSLSV6MkBCgbJZOUlITiYv0l6J988slaB/WoUSnlcLU2wbWbt3HlRoFeEqLrlMr+INTEvDfYD7FJN3EsKRtTfzuB1S8FsX8IEemp0YypTz31FE6ePAmZTKZbLbf8l4tGU/nU43R/nnZmuiSki6etbvuF9DwAZSMQiJoSpUKOr57zx8D5u7Hv/A1sO52GQe2qnv+HiB49Bg/RnTx5Mry8vJCeng5TU1OcPn0au3fvRmBgYIVZS6n6PO60dFzKzNPbfja1bPKnVk4WDR4TUW152pvh1Z7eAIBPtsSjuFQrcURE1JgYnITExMTgo48+gr29PeRyOeRyOXr06IHIyEi8+eab9RHjI6GFozkAICH1nxknbxWW6IbntnJmEkJN0+t9fGBvrkZSVgE2HOP8IUT0D4OTEI1GAwuLsgeivb09rl+/DgDw8PBAQkJC3Ub3CGnrVjbnyunr/6zgey6trFXEyVINa1OVJHER1ZaZWol/9SprDVkcfQGlGraGEFEZg5OQdu3a4fjx4wCAoKAgfPbZZ9i3bx8++ugjeHt713mAjwq/Oy0dKTmFyMov6+x7+noOAKCVc8OuZUNU154Pag5rUyNcvlGAzSdTpA6HiBoJg5OQDz/8EFpt2V8yH330ES5duoSePXtiy5Yt+Oabb+o8wEeFhbERPO/0CzmZXJZ8HLl8EwAQ0NxGsriI6oKZWomwbl4AgOX7LksbDBE1GgYnIaGhoXj66acBAL6+vjh79iwyMzORnp6Ofv361XmAj5IAj7JRMfsvZEIIgSOXswAAXTyZhFDTN/qx5lAp5Ii7mo3jV7OlDoeIGgGDkpCSkhIolUqcOnVKb7utrS3H/9eBni3sAQC7z2XibOotXM8phEoph39za2kDI6oD9uZqDOngAgD4IeaKxNEQUWNgUBJiZGSE5s2bcy6QetKjhT0UchniU3IR+edZAECflg4wVdV4TjmiRmVssAcA4H8nruv6PhHRo8vg1zEffPAB3n//fWRlZdVHPI80e3M1QtuWrR68+1wGAOC5wKa/ICBROX93a3RoZoXiUi3WHE6SOhwikpjBScjChQuxe/duuLq6olWrVujcubPeh2rn3VA/2JqVDccd0MYJ/Vs7ShwRUd2RyWQYG+wJAPjxQBI0WoMW8Saih4zB7fzDhg2rhzConKe9GaLCeyMpqwDt3KzY14YeOo93cMGczWeQnH0bUfFpGNiWU7kTPapkonzxF9LJzc2FlZUVcnJyYGnJOTqI6trcrWexOPoCevjaY/XLQVKHQ0R1yJBnqMGvY4iIamt0UHPIZcDe85k4n37rwQcQ0UPJ4CRELpdDoVBU+SEiepBmNqbo37qsE/YqDtclemQZ3Cdkw4YNet9LSkpw7NgxrFy5ErNmzaqzwIjo4TYu2BPbz6Tht6PJeGeQH8zVHIpO9Kgx+P/1Q4cOrbBt+PDhaNu2LdauXYuXXnqpTgIjoodbd187eDuY4WJGPjYcvYYxd0bNENGjo876hDz22GOIioqqq+qI6CEnk8kw7k7i8f2+y1xdl+gRVCdJyO3bt/HNN9/Azc2tLqojokfEMwHNYGNqhEuZ+fjfietSh0NEDczg1zE2NjZ6c1cIIXDr1i2Ymppi9erVdRocET3czNVKvNLLG59tTcA3UefxRAdXKBUctEf0qDA4Cfnqq6/0khC5XA4HBwcEBQXBxoarvRKRYcYGe2Lp7ou4lJmPX2OvYVTX5lKHREQNhJOVVYKTlRE1rGV7L2H2H2dgY2qEnVP6wObO0gVE1PTU62Rly5cvx6+//lph+6+//oqVK1caWh0REcYFe8DP2QI3C0owZ0u81OEQUQMxOAmJjIyEvb19he2Ojo745JNP6iQoInq0KBVyfDysHWQyYF3sNWw6zk6qRI8Cg5OQpKQkeHl5Vdju4eGBpCQuzU1ENRPoaYs3+voCAN5ffxLxKbkSR0RE9c3gJMTR0REnTpyosP348eOws7Ork6CI6NE0uX8LPOZti7yiUoz7/hCu3SyQOiQiqkcGJyGjRo3Cm2++iV27dkGj0UCj0WDnzp2YPHkyRo4cWR8xEtEjQqmQ49sXAtHKyQLpt4rw/NKDTESIHmIGj44pLi7GmDFj8Ouvv0KpLBvhq9VqMXbsWCxZsgQqVdPv1c7RMUTSSsm5jZHfHcCVGwVwtTLGT688Bk97M6nDIqJqMOQZWuMhuomJiYiLi4OJiQnat28PDw+PGgXbGDEJIZJeak4hRv/3AC5k5MPRQo0fXw5CCycLqcMiogeo1yG65Vq0aIFnn30Wjz/+eK0TkEWLFsHT0xPGxsYICgrCoUOHqiy7fv16BAYGwtraGmZmZvD398eqVat0+0tKSjB16lS0b98eZmZmcHV1xdixY3H9OnvbEzUlzlbGWPNqMPycy17NjFp6EBcz8qQOi4jqkMFJyDPPPIO5c+dW2P7ZZ5/h2WefNTiAtWvXIjw8HDNmzMDRo0fRsWNHhIaGIj09vdLytra2+OCDDxATE4MTJ04gLCwMYWFh2LZtGwCgoKAAR48exbRp03D06FGsX78eCQkJePLJJw2OjYik5WChxs+vPIbWLpbIzCvC6P8exNUs9hEhelgY/DrGwcEBO3fuRPv27fW2nzx5EiEhIUhLSzMogKCgIHTp0gULFy4EUNa/xN3dHZMmTcJ7771XrTo6d+6MIUOGYPbs2ZXuP3z4MLp27YorV66gefMHTwnN1zFEjcuNvCKM+O4Azqfnwd3WBL+91g2OlsZSh0VElajX1zF5eXmVdj41MjJCbq5h4/qLi4sRGxuLkJCQfwKSyxESEoKYmJgHHi+EQFRUFBISEtCrV68qy+Xk5EAmk8Ha2rrS/UVFRcjNzdX7EFHjYWeuxk8vB8HTzhRXs27jxZWHkV9UKnVYRFRLBich7du3x9q1aytsX7NmDdq0aWNQXZmZmdBoNHByctLb7uTkhNTU1CqPy8nJgbm5OVQqFYYMGYIFCxZgwIABlZYtLCzE1KlTMWrUqCozssjISFhZWek+7u7uBl0HEdU/R0tj/PBiEOzMVDiVnIs3fz4GjZZLXxE1ZQavojtt2jQ8/fTTuHDhAvr16wcAiIqKwk8//YR169bVeYCVsbCwQFxcHPLy8hAVFYXw8HB4e3ujT58+euVKSkrw3HPPQQiBxYsXV1lfREQEwsPDdd9zc3OZiBA1Qs3tTLF0XCBGfXcAUWfTMet/pzHrybZ6K3sTUdNhcBLyxBNPYOPGjfjkk0+wbt06mJiYoGPHjti5cydsbW0Nqsve3h4KhaJCP5K0tDQ4OztXeZxcLoevb9n0zv7+/oiPj0dkZKReElKegFy5cgU7d+6873sptVoNtVptUOxEJI3OzW0wf4Q/Jvx0FD/EXEFzW1O83NNb6rCIqAZqNER3yJAh2LdvH/Lz83Hx4kU899xzePvtt9GxY0eD6lGpVAgICEBUVJRum1arRVRUFIKDg6tdj1arRVFRke57eQKSmJiIHTt2cDp5oofM4PYuiBjsBwD4eHM8Nhy7JnFERFQTBreElNu9ezeWLVuG3377Da6urnj66aexaNEig+sJDw/HuHHjEBgYiK5du2L+/PnIz89HWFgYAGDs2LFwc3NDZGQkgLL+G4GBgfDx8UFRURG2bNmCVatW6V63lJSUYPjw4Th69Cj++OMPaDQaXf8SW1vbh2JGVyICXunpjevZhVix/zLe/vUErEyM0M/P6cEHElGjYVASkpqaihUrVmDZsmXIzc3Fc889h6KiImzcuNHgTqnlRowYgYyMDEyfPh2pqanw9/fH1q1bdZ1Vk5KSIJf/02CTn5+PCRMm4Nq1azAxMYGfnx9Wr16NESNGAACSk5OxadMmAGWvau62a9euCv1GiKhpkslkmP54G+TcLsGGY8l4ffVRrHyxKx7zZssnUVNR7XlCnnjiCezevRtDhgzB6NGjMWjQICgUChgZGeH48eM1TkIaI84TQtR0lGi0eH11LHbEp8PYSI4lLwSgTytHqcMiemTVyzwhf/75J1566SXMmjULQ4YMgUKhqHWgRES1ZaSQY+HzndHPzxGFJVq88sMRbDmZInVYRFQN1U5C9u7di1u3biEgIABBQUFYuHAhMjMz6zM2IqJqMTZSYMkLAXi8gwtKNAITfzqKb/++gBquz0lEDaTaSchjjz2GpUuXIiUlBf/617+wZs0auLq6QqvVYvv27bh161Z9xklEdF8qpRxfj+yEMY95QAgg8s+zeGfdCRSVaqQOjYiqYPDaMXdLSEjAsmXLsGrVKmRnZ2PAgAG6TqFNGfuEEDVdQgj8EHMFs/53GloBdPG0waLRneFowbVmiBpCva4dc7dWrVrhs88+w7Vr1/Dzzz/Xpioiojohk8kwrpsnlod1hYVaicOXb+Lxb/biyOUsqUMjonvUqiXkYcWWEKKHw4WMPLy2KhaJ6XlQymX4cEhrjOvmyWneiepRg7WEEBE1Zj4O5tg4sTse7+CCUq3AzP+dwVtr41BQzBV4iRoDJiFE9FAzUyuxYFQnTHu8DRRyGX6Pu46nFu3Hpcx8qUMjeuQxCSGih55MJsNLPbzw8yuPwd5cjYS0W3hiwV78dDCJw3iJJMQkhIgeGV29bLH5zR7o4mmDvKJSvL/hJEZ8dwCHLrHTKpEU2DG1EuyYSvRw02gFlu+7hC/+SkBhiRYA0MrJAn38HNDC0QK2ZkYwNlJArVRArZRDrZRDpZTDzlwNc3WN1/0keiQY8gxlElIJJiFEj4ZrNwvwn+gLWHfkGoo12modY2+ugreDOQI8bNDVyxbB3nYwNuIyFkTlmITUEpMQokdLdkExdp5Nx9Gkm7iYkY+8olIUFGtQXKpFUWn5/2pRUFxx9lULtRKD2zvjxR5e8HPm7wsiJiG1xCSEiCqTW1iCpBsFOJOSiyOXs7A3MRPXcwp1+x/v4ILpj7eBoyVnZ6VHF5OQWmISQkTVodUKHLlyEyv3X8aWUykQArAyMcInT7XHkA4uUodHJAlOVkZE1ADkchm6etli0ejO+GNSD7R3s0LO7RJM/OkovtiWAK2Wf+MR3Q+TECKiOtDW1QobJnTDq728AQALd53Hu7+dgIaJCFGVmIQQEdURpUKO9/+vNb54tiMUchnWxV7DW2vjUFLNkTdEjxomIUREdWx4QDMsHNUJRgoZ/nf8Ot78+RgTEaJKMAkhIqoHg9u74NsxAVAp5PjzVCre+OkoikuZiBDdjUkIEVE96efnhG/HBkCllGPb6TQmIkT3YBJCRFSP+rZyxHdjyhKRv86kYcKPTESIyjEJISKqZ31aOWLp2EColHLsiE/DhB9jUVRacfZVokcNkxAiogbQu6UD/js2EGqlHDvi0/H66qNMROiRxySEiKiB9GrpgGXjukCtlGPn2XQ8v/QgUu+a9p3oUcMkhIioAfVoYY/l47vAwliJ2Cs3MeSbPfg9LhlcQYMeRUxCiIgaWDdfe/wxqQfauFjiRn4xJq+Jw7D/7MfvcckoKC6VOjyiBsMF7CrBBeyIqCEUlWqwdPdFLNx1HoUlZSNmVEo5grxs0d3XHt187NDW1QoKuUziSImqj6vo1hKTECJqSOm3CvHTwSSsi72Gazdv6+2zNFbiMW87dPe1x5MdXWFjppIoSqLqYRJSS0xCiEgKQghcyMjD3+cyEXMhEwcvZuFW0T+vZ4yN5HiqUzNM7OuDZjamEkZKVDUmIbXEJISIGoNSjRanrudi/4VMbD6RgtPXcwGUvbIJ6+aJCX19YWViJHGURPoMeYZK3jF10aJF8PT0hLGxMYKCgnDo0KEqy65fvx6BgYGwtraGmZkZ/P39sWrVqgplBg4cCDs7O8hkMsTFxdXzFRAR1Q+lQg5/d2tM6OOLPyb1wNpXH0Owtx2KS7X4dvdFhHz5N/48mcKRNdRkSZqErF27FuHh4ZgxYwaOHj2Kjh07IjQ0FOnp6ZWWt7W1xQcffICYmBicOHECYWFhCAsLw7Zt23Rl8vPz0aNHD8ydO7ehLoOIqN7JZDIEedvhp1eCsHx8F3jbmyHjVhFe//Eo/rUqFum5nG+Emh5JX8cEBQWhS5cuWLhwIQBAq9XC3d0dkyZNwnvvvVetOjp37owhQ4Zg9uzZetsvX74MLy8vHDt2DP7+/gbFxdcxRNTYFZZosGjXeSyOvoBSrYCdmQpfjvBH75YOUodGj7gm8TqmuLgYsbGxCAkJ+ScYuRwhISGIiYl54PFCCERFRSEhIQG9evWqVSxFRUXIzc3V+xARNWbGRgpMGdgK/5vUA37OFriRX4xx3x/Cp3+ehUbL1zPUNEiWhGRmZkKj0cDJyUlvu5OTE1JTU6s8LicnB+bm5lCpVBgyZAgWLFiAAQMG1CqWyMhIWFlZ6T7u7u61qo+IqKG0drHExond8cJjzQEAS/6+gFd+OIK8Ik56Ro2f5B1TDWVhYYG4uDgcPnwYc+bMQXh4OKKjo2tVZ0REBHJycnSfq1ev1k2wREQNwNhIgY+HtceCUZ1069IMX7wf17NvP/hgIgkppTqxvb09FAoF0tLS9LanpaXB2dm5yuPkcjl8fX0BAP7+/oiPj0dkZCT69OlT41jUajXUanWNjyciagye6OgKd1tTvLzyCM6m3sJT/9mH5eO7oo0r+7ZR4yRZS4hKpUJAQACioqJ027RaLaKiohAcHFzterRaLYqKiuojRCKiJsff3RobJ3ZDSydzpOUW4blvY7DvfKbUYRFVStLXMeHh4Vi6dClWrlyJ+Ph4vP7668jPz0dYWBgAYOzYsYiIiNCVj4yMxPbt23Hx4kXEx8dj3rx5WLVqFV544QVdmaysLMTFxeHMmTMAgISEBMTFxd23nwkR0cOkmY0pfv1XNwR52SKvqBTjlx/C73HJUodFVIFkr2MAYMSIEcjIyMD06dORmpoKf39/bN26VddZNSkpCXL5P3lSfn4+JkyYgGvXrsHExAR+fn5YvXo1RowYoSuzadMmXRIDACNHjgQAzJgxAzNnzmyYCyMikpiVqRF+eKkrwn85js0nUjB5TRyuZxfitd7ekMm4IB41Dpy2vRKcJ4SIHhZarcCcLfFYtvcSAGBcsAemP9GWK/NSvWkS84QQEVH9k8tlmPZ4G3w4pDVkMmBlzBVM+DEWhSUaqUMjYhJCRPQoeLmnNxaO6gyVQo5tp9Mw+r8HcTO/WOqw6BHHJISI6BExpIMLVr3UFZbGSsReuYlnluzH1awCqcOiRxiTECKiR0iQtx3Wvd4NrlbGuJiRj6f+sx+nknOkDoseUUxCiIgeMS2dLLB+Qnf4OVsgM68II76NwdZTnMaAGh6TECKiR5CzlTF+eS0Y3X3tkF+swWurYzFz02kUlbLDKjUcJiFERI8oS2MjrAjrin/18gYArNh/Gc8s3o/EtFsSR0aPCiYhRESPMCOFHBH/1xrLx3eBjakRTiXnYsg3e/H1jkQUl2qlDo8eckxCiIgIff0c8efkXujv54hijRZf7TiHJxbsxdGkm1KHRg8xJiFERASgrJ/If8cF4ptRnWBnpkJC2i08s3g/Ptx4ErmFJVKHRw8hJiFERKQjk8nwZEdXbA/vjeEBzSAEsPpAEvrP+xubT6SAK31QXWISQkREFdiaqfDFsx3x0ytB8LY3Q8atIkz86SheXHGYE5xRnWESQkREVermY48tk3ticv8WUCnk2JWQgYFf7cZ3uy+gVMOOq1Q7TEKIiOi+jI0U+PeAltgyuSe6etnidokGn2w5i+f/exAZt4qkDo+aMCYhRERULb6O5lj76mP47JkOMFcrcehSFh5fsIcjaKjGmIQQEVG1yWQyPNfFHRsndoePgxnScsumfV9zKEnq0KgJYhJCREQG83U0x+9v9MDgds4o0Qi8t/4kPtx4khOckUGYhBARUY2Yq5X4z+jOeCe0FWSysqG8o/97gP1EqNqYhBARUY3JZDJM7OuLZeMCYaFW4vDlm3hiwV4cv5otdWjUBDAJISKiWuvn54SNb5T1E0nNLcSzS2KwaNd5lHAYL90HkxAiIqoTPg7m2DixOwa2cUKxRovPtyXgyYX7sP9CptShUSMlE5yDt4Lc3FxYWVkhJycHlpaWUodDRNSkCCGwMS4ZH/3vDG4WlK05093XDi/38Eavlg5QyGUSR0j1yZBnKJOQSjAJISKqvcy8IizceR4/HryCEk3Zo8bFyhj9Wzuih68DOrpbwdnSGDIZk5KHCZOQWmISQkRUd67dLMD3ey9j/bFryC7QX43X2tQIbVws0aGZNfzdrdHZwxqOFsYSRUp1gUlILTEJISKqe4UlGuxNzMSexAwcuJiF8xl50GgrPoI6NbfGkPYuGB7QDNamKgkipdpgElJLTEKIiOpfYYkG59PzcCo5B3FXsxF3NRsJabdQ/lQyNpJjeEAzvNbbB81sTKUNlqqNSUgtMQkhIpJGWm4htp5KxdrDV3EmJRcAoFLI8XxQc7zRzxf25mqJI6QHYRJSS0xCiIikJYTAgYtZWLAzEfsv3AAAmKoUeKmHF17q4cXXNI0Yk5BaYhJCRNR47E3MxGfbzuLEtRwAZdPFjw32wMs9vWFrxmSksWESUktMQoiIGhchBLadTsX8HYk4m3oLAGBipMCwTq4YHeSBdm5WEkdI5ZiE1BKTECKixkmrFdgRn4ZvdibiVHKubru/uzWeCWiGwe2c2W9EYkxCaolJCBFR4yaEwMFLWVh94Aq2nU7VTYYmlwHdfOzxf+1dMKCNExwsmJA0NEOeoY1i7ZhFixbB09MTxsbGCAoKwqFDh6osu379egQGBsLa2hpmZmbw9/fHqlWr9MoIITB9+nS4uLjAxMQEISEhSExMrO/LICKiBiKTyfCYtx0WPt8Z+9/rj4jBfmjvZgWtAPaez8T7G06i6yc78OyS/fjvnou4mlUgdchUCclbQtauXYuxY8diyZIlCAoKwvz58/Hrr78iISEBjo6OFcpHR0fj5s2b8PPzg0qlwh9//IEpU6Zg8+bNCA0NBQDMnTsXkZGRWLlyJby8vDBt2jScPHkSZ86cgbHxg2fiY0sIEVHTdOVGPv44kYJtp1N1HVnLtXGxRGhbZwzp4AJfR3OJInz4NanXMUFBQejSpQsWLlwIANBqtXB3d8ekSZPw3nvvVauOzp07Y8iQIZg9ezaEEHB1dcWUKVPw9ttvAwBycnLg5OSEFStWYOTIkQ+sj0kIEVHTdz37Nv46nYqtp1Nx6FIW7p6cdUAbJ0zq54sOzawli+9h1WRexxQXFyM2NhYhISG6bXK5HCEhIYiJiXng8UIIREVFISEhAb169QIAXLp0CampqXp1WllZISgoqMo6i4qKkJubq/chIqKmzdXaBOO7e2HNq8E48uEAfDa8A/r5OUImA7afScOTC/dh4k9Hce0mX9VIRdIkJDMzExqNBk5OTnrbnZyckJqaWuVxOTk5MDc3h0qlwpAhQ7BgwQIMGDAAAHTHGVJnZGQkrKysdB93d/faXBYRETUytmYqPBfoju/Hd8H2f/fG053cIJcBm0+koP+8v/HV9nO4XayROsxHTqPomGooCwsLxMXF4fDhw5gzZw7Cw8MRHR1d4/oiIiKQk5Oj+1y9erXugiUiokbF19EcX47wx/8m9UBXL1sUlWrxdVQi+s+LxuYTKeCg0YajlPLk9vb2UCgUSEtL09uelpYGZ2fnKo+Ty+Xw9fUFAPj7+yM+Ph6RkZHo06eP7ri0tDS4uLjo1env719pfWq1Gmo1h3ERET1K2rpaYe2rj2HLyVR8siUeydm3MfGnowj2tsPMJ9uilbOF1CE+9CRtCVGpVAgICEBUVJRum1arRVRUFIKDg6tdj1arRVFREQDAy8sLzs7OenXm5ubi4MGDBtVJREQPP5lMhiEdXLAjvDcm928BtVKOmIs38H/f7MHMTaeRU1AidYgPNUlbQgAgPDwc48aNQ2BgILp27Yr58+cjPz8fYWFhAICxY8fCzc0NkZGRAMr6bwQGBsLHxwdFRUXYsmULVq1ahcWLFwMo+4F666238PHHH6NFixa6Ibqurq4YNmyYVJdJRESNmIlKgX8PaInhAc0wZ3M8tp5OxYr9l/F7XDLCB7bCswHNYGykkDrMh47kSciIESOQkZGB6dOnIzU1Ff7+/ti6dauuY2lSUhLk8n8abPLz8zFhwgRcu3YNJiYm8PPzw+rVqzFixAhdmXfffRf5+fl49dVXkZ2djR49emDr1q3VmiOEiIgeXe62plgyJgB7EzMx63+nkZieh2kbT+Gr7efwbEAzDGzrDH93ayjkMqlDfShIPk9IY8R5QoiIqESjxY8HrmDpnktIzr6t226hVqKNqyXaulqhtYsFWrtYwtfRnC0ldzSpycoaIyYhRERUrlSjxY74dGw+mYLohHTcKiytUEYhl8Hb3gx+LpZo7WKBVk4W8HU0RzMb00eu1YRJSC0xCSEiosqUarQ4n5GHU8m5OJWcg7OpuTibegvZVXRgVSvl8LI3g4+jObztzeBlbwZvB3N42ZvBysSogaNvGExCaolJCBERVZcQAmm5RYhPzUV8Si7iU24hMe0WLmbmo7hUW+Vxfs4W6N/aEcMD3OFlb9aAEdcvJiG1xCSEiIhqS6MVuJpVgPPpebiUmY+Lmfm4lFn232m5RXpl+/k5InxAS7Rzs5Io2rrDJKSWmIQQEVF9ysovxu5zGfg9Lhm7EjJ024f5u+KdQX5wszaRMLraYRJSS0xCiIiooVzKzMfXO85hY9x1AGX9SF7t5Y3XevvATC35TBoGYxJSS0xCiIiooZ28loOPN5/BwUtZAABHCzXeCW2FZzo3g7wJjbBhElJLTEKIiEgKQghsO52GT7bEIymrAADQzs0SUwa0Qu+WDk0iGWESUktMQoiISEpFpRqs3H8ZC6LO41ZR2bwkzW1NMaKLOx7v4AIPu8Y7moZJSC0xCSEiosYgM68IS6Iv4JcjV5F71yRpbVwsMaSDC/6vvUujG97LJKSWmIQQEVFjUlBcij+Op+B/J65j/4Ub0Gj/eXS3drHE440oIWESUktMQoiIqLG6mV+Mv86kYvPJVOw/n4nSexKSwe2c8X/tneHraCFJfExCaolJCBERNQX3S0h8Hc3Ru6UDOjSzQgtHCzhYqGFpooRcJoNcVtbBVQgBrQBUSnlVpzAYk5BaYhJCRERNzc38YmyPT8OfJ1Ow93wmSjTVe7xbmRjh+IyBdRaHIc/QpjcLChEREVVgY6bCc4HueC7QHTm3SxCdkI6jV27i+LUcXLtZgBv5xais2UHKtggmIURERA8ZKxMjDPV3w1B/N922Eo0Wt0s0EFpAIwRkAOQyGWR19ybGYExCiIiIHgFGCjmMFBJmHJVoXNEQERHRI4NJCBEREUmCSQgRERFJgkkIERERSYJJCBEREUmCSQgRERFJgkkIERERSYJJCBEREUmCSQgRERFJgkkIERERSYJJCBEREUmCSQgRERFJgkkIERERSYJJCBEREUmCSQgRERFJQvIkZNGiRfD09ISxsTGCgoJw6NChKssuXboUPXv2hI2NDWxsbBASElKhfFpaGsaPHw9XV1eYmppi0KBBSExMrO/LICIiIgNJmoSsXbsW4eHhmDFjBo4ePYqOHTsiNDQU6enplZaPjo7GqFGjsGvXLsTExMDd3R0DBw5EcnIyAEAIgWHDhuHixYv4/fffcezYMXh4eCAkJAT5+fkNeWlERET0ADIhhJDq5EFBQejSpQsWLlwIANBqtXB3d8ekSZPw3nvvPfB4jUYDGxsbLFy4EGPHjsW5c+fQqlUrnDp1Cm3bttXV6ezsjE8++QQvv/xyteLKzc2FlZUVcnJyYGlpWfMLJCIiesQY8gyVrCWkuLgYsbGxCAkJ+ScYuRwhISGIiYmpVh0FBQUoKSmBra0tAKCoqAgAYGxsrFenWq3G3r17q6ynqKgIubm5eh8iIiKqX5IlIZmZmdBoNHByctLb7uTkhNTU1GrVMXXqVLi6uuoSGT8/PzRv3hwRERG4efMmiouLMXfuXFy7dg0pKSlV1hMZGQkrKyvdx93dveYXRkRERNUiecfUmvr000+xZs0abNiwQdfyYWRkhPXr1+PcuXOwtbWFqakpdu3ahcGDB0Mur/pSIyIikJOTo/tcvXq1oS6DiIjokaWU6sT29vZQKBRIS0vT256WlgZnZ+f7HvvFF1/g008/xY4dO9ChQwe9fQEBAYiLi0NOTg6Ki4vh4OCAoKAgBAYGVlmfWq2GWq2u+cUQERGRwSRrCVGpVAgICEBUVJRum1arRVRUFIKDg6s87rPPPsPs2bOxdevW+yYWVlZWcHBwQGJiIo4cOYKhQ4fWafxERERUO5K1hABAeHg4xo0bh8DAQHTt2hXz589Hfn4+wsLCAABjx46Fm5sbIiMjAQBz587F9OnT8dNPP8HT01PXd8Tc3Bzm5uYAgF9//RUODg5o3rw5Tp48icmTJ2PYsGEYOHCgNBdJRERElZI0CRkxYgQyMjIwffp0pKamwt/fH1u3btV1Vk1KStLry7F48WIUFxdj+PDhevXMmDEDM2fOBACkpKQgPDwcaWlpcHFxwdixYzFt2rQGuyYiIiKqHknnCWmsOE8IERFRzTSJeUKIiIjo0cYkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCTBJISIiIgkwSSEiIiIJMEkhIiIiCQheRKyaNEieHp6wtjYGEFBQTh06FCVZZcuXYqePXvCxsYGNjY2CAkJqVA+Ly8Pb7zxBpo1awYTExO0adMGS5Ysqe/LICIiIgNJmoSsXbsW4eHhmDFjBo4ePYqOHTsiNDQU6enplZaPjo7GqFGjsGvXLsTExMDd3R0DBw5EcnKyrkx4eDi2bt2K1atXIz4+Hm+99RbeeOMNbNq0qaEui4iIiKpBJoQQUp08KCgIXbp0wcKFCwEAWq0W7u7umDRpEt57770HHq/RaGBjY4OFCxdi7NixAIB27dphxIgRmDZtmq5cQEAABg8ejI8//rhaceXm5sLKygo5OTmwtLSswZURERE9mgx5hiobKKYKiouLERsbi4iICN02uVyOkJAQxMTEVKuOgoIClJSUwNbWVretW7du2LRpE1588UW4uroiOjoa586dw1dffVVlPUVFRSgqKtJ9z8nJAVB2I4mIiKj6yp+d1WrjEBJJTk4WAMT+/fv1tr/zzjuia9eu1arj9ddfF97e3uL27du6bYWFhWLs2LECgFAqlUKlUomVK1fet54ZM2YIAPzwww8//PDDTx19rl69+sDnuGQtIbX16aefYs2aNYiOjoaxsbFu+4IFC3DgwAFs2rQJHh4e2L17NyZOnAhXV1eEhIRUWldERATCw8N137VaLbKysmBnZweZTFYn8ebm5sLd3R1Xr17lK546wntat3g/6x7vad3i/ax79XFPhRC4desWXF1dH1hWsiTE3t4eCoUCaWlpetvT0tLg7Ox832O/+OILfPrpp9ixYwc6dOig23779m28//772LBhA4YMGQIA6NChA+Li4vDFF19UmYSo1Wqo1Wq9bdbW1jW4qgeztLTk/3nqGO9p3eL9rHu8p3WL97Pu1fU9tbKyqlY5yUbHqFQqBAQEICoqSrdNq9UiKioKwcHBVR732WefYfbs2di6dSsCAwP19pWUlKCkpARyuf5lKRQKaLXaur0AIiIiqhVJX8eEh4dj3LhxCAwMRNeuXTF//nzk5+cjLCwMADB27Fi4ubkhMjISADB37lxMnz4dP/30Ezw9PZGamgoAMDc3h7m5OSwtLdG7d2+88847MDExgYeHB/7++2/88MMP+PLLLyW7TiIiIqpI0iRkxIgRyMjIwPTp05Gamgp/f39s3boVTk5OAICkpCS9Vo3FixejuLgYw4cP16tnxowZmDlzJgBgzZo1iIiIwOjRo5GVlQUPDw/MmTMHr732WoNdV2XUajVmzJhR4bUP1Rzvad3i/ax7vKd1i/ez7kl9TyWdJ4SIiIgeXZJP205ERESPJiYhREREJAkmIURERCQJJiFEREQkCSYhDWTRokXw9PSEsbExgoKCcOjQIalDahIiIyPRpUsXWFhYwNHREcOGDUNCQoJemcLCQkycOBF2dnYwNzfHM888U2ESPKrcp59+CplMhrfeeku3jffTcMnJyXjhhRdgZ2cHExMTtG/fHkeOHNHtF0Jg+vTpcHFxgYmJCUJCQpCYmChhxI2bRqPBtGnT4OXlBRMTE/j4+GD27Nl6a5HwnlZt9+7deOKJJ+Dq6gqZTIaNGzfq7a/OvcvKysLo0aNhaWkJa2trvPTSS8jLy6v7YKu1SAvVypo1a4RKpRLff/+9OH36tHjllVeEtbW1SEtLkzq0Ri80NFQsX75cnDp1SsTFxYn/+7//E82bNxd5eXm6Mq+99ppwd3cXUVFR4siRI+Kxxx4T3bp1kzDqpuHQoUPC09NTdOjQQUyePFm3nffTMFlZWcLDw0OMHz9eHDx4UFy8eFFs27ZNnD9/Xlfm008/FVZWVmLjxo3i+PHj4sknnxReXl56617RP+bMmSPs7OzEH3/8IS5duiR+/fVXYW5uLr7++mtdGd7Tqm3ZskV88MEHYv369QKA2LBhg97+6ty7QYMGiY4dO4oDBw6IPXv2CF9fXzFq1Kg6j5VJSAPo2rWrmDhxou67RqMRrq6uIjIyUsKomqb09HQBQPz9999CCCGys7OFkZGR+PXXX3Vl4uPjBQARExMjVZiN3q1bt0SLFi3E9u3bRe/evXVJCO+n4aZOnSp69OhR5X6tViucnZ3F559/rtuWnZ0t1Gq1+PnnnxsixCZnyJAh4sUXX9Tb9vTTT4vRo0cLIXhPDXFvElKde3fmzBkBQBw+fFhX5s8//xQymUwkJyfXaXx8HVPPiouLERsbq7dujVwuR0hICGJiYiSMrGnKyckBANja2gIAYmNjUVJSond//fz80Lx5c97f+5g4cSKGDBlSYT0l3k/Dbdq0CYGBgXj22Wfh6OiITp06YenSpbr9ly5dQmpqqt49tbKyQlBQEO9pFbp164aoqCicO3cOAHD8+HHs3bsXgwcPBsB7WhvVuXcxMTGwtrbWWxolJCQEcrkcBw8erNN4muwquk1FZmYmNBqNbhbYck5OTjh79qxEUTVNWq0Wb731Frp374527doBAFJTU6FSqSosOOjk5KSb1p/0rVmzBkePHsXhw4cr7OP9NNzFixexePFihIeH4/3338fhw4fx5ptvQqVSYdy4cbr7VtnvAN7Tyr333nvIzc2Fn58fFAoFNBoN5syZg9GjRwMA72ktVOfepaamwtHRUW+/UqmEra1tnd9fJiHUZEycOBGnTp3C3r17pQ6lybp69SomT56M7du3w9jYWOpwHgparRaBgYH45JNPAACdOnXCqVOnsGTJEowbN07i6JqmX375BT/++CN++ukntG3bFnFxcXjrrbfg6urKe/qQ4euYemZvbw+FQlFhdEFaWhqcnZ0liqrpeeONN/DHH39g165daNasmW67s7MziouLkZ2drVee97dysbGxSE9PR+fOnaFUKqFUKvH333/jm2++gVKphJOTE++ngVxcXNCmTRu9ba1bt0ZSUhIA6O4bfwdU3zvvvIP33nsPI0eORPv27TFmzBj8+9//1i1myntac9W5d87OzkhPT9fbX1paiqysrDq/v0xC6plKpUJAQACioqJ027RaLaKiohAcHCxhZE2DEAJvvPEGNmzYgJ07d8LLy0tvf0BAAIyMjPTub0JCApKSknh/K9G/f3+cPHkScXFxuk9gYCBGjx6t+2/eT8N07969wrDxc+fOwcPDAwDg5eUFZ2dnvXuam5uLgwcP8p5WoaCgQG/xUgBQKBTQarUAeE9rozr3Ljg4GNnZ2YiNjdWV2blzJ7RaLYKCguo2oDrt5kqVWrNmjVCr1WLFihXizJkz4tVXXxXW1tYiNTVV6tAavddff11YWVmJ6OhokZKSovsUFBToyrz22muiefPmYufOneLIkSMiODhYBAcHSxh103L36BgheD8NdejQIaFUKsWcOXNEYmKi+PHHH4WpqalYvXq1rsynn34qrK2txe+//y5OnDghhg4dyuGk9zFu3Djh5uamG6K7fv16YW9vL959911dGd7Tqt26dUscO3ZMHDt2TAAQX375pTh27Ji4cuWKEKJ6927QoEGiU6dO4uDBg2Lv3r2iRYsWHKLblC1YsEA0b95cqFQq0bVrV3HgwAGpQ2oSAFT6Wb58ua7M7du3xYQJE4SNjY0wNTUVTz31lEhJSZEu6Cbm3iSE99Nw//vf/0S7du2EWq0Wfn5+4rvvvtPbr9VqxbRp04STk5NQq9Wif//+IiEhQaJoG7/c3FwxefJk0bx5c2FsbCy8vb3FBx98IIqKinRleE+rtmvXrkp/b44bN04IUb17d+PGDTFq1Chhbm4uLC0tRVhYmLh161adxyoT4q4p6IiIiIgaCPuEEBERkSSYhBAREZEkmIQQERGRJJiEEBERkSSYhBAREZEkmIQQERGRJJiEEBERkSSYhBAREZEkmIQQUaM3c+ZMODk5QSaTYePGjdU6Jjo6GjKZrMJifA+jy5cvQyaTIS4urt7PZci/AdGDMAkhqoHx48dDJpNBJpNBpVLB19cXH330EUpLS6UO7YGa2kMkPj4es2bNwrfffouUlBQMHjy43s7Vp08fvPXWW/VW/4PUNHFyd3dHSkoK2rVrVz+BEdUTpdQBEDVVgwYNwvLly1FUVIQtW7Zg4sSJMDIyQkREhMF1aTQayGSyCiuHEnDhwgUAwNChQyGTySSOpmaEENBoNFAq6+dXrkKh4BL21CTxNx5RDanVajg7O8PDwwOvv/46QkJCsGnTJgBAUVER3n77bbi5ucHMzAxBQUGIjo7WHbtixQpYW1tj06ZNaNOmDdRqNZKSklBUVISpU6fC3d0darUavr6+WLZsme64U6dOYfDgwTA3N4eTkxPGjBmDzMxM3f4+ffrgzTffxLvvvgtbW1s4Oztj5syZuv2enp4AgKeeegoymUz3/cKFCxg6dCicnJxgbm6OLl26YMeOHXrXm5KSgiFDhsDExAReXl746aef4Onpifnz5+vKZGdn4+WXX4aDgwMsLS3Rr18/HD9+/L738eTJk+jXrx9MTExgZ2eHV199FXl5eQDKXsM88cQTAAC5XH7fJGTLli1o2bIlTExM0LdvX1y+fFlv/40bNzBq1Ci4ubnB1NQU7du3x88//6zbP378ePz999/4+uuvda1cly9fhkajwUsvvQQvLy+YmJigVatW+Prrr+97TeUtGn/++ScCAgKgVquxd+9eaLVaREZG6urq2LEj1q1bB6DslUrfvn0BADY2NpDJZBg/fjwAYOvWrejRowesra1hZ2eHxx9/XJeclR979+uY8vNHRUUhMDAQpqam6NatGxISEvTi/P3339G5c2cYGxvD29sbs2bN0mvNS0xMRK9evWBsbIw2bdpg+/bt971uIoPV+ZJ4RI+AcePGiaFDh+pte/LJJ0Xnzp2FEEK8/PLLolu3bmL37t3i/Pnz4vPPPxdqtVqcO3dOCCHE8uXLhZGRkejWrZvYt2+fOHv2rMjPzxfPPfeccHd3F+vXrxcXLlwQO3bsEGvWrBFCCHHz5k3h4OAgIiIiRHx8vDh69KgYMGCA6Nu3ry6G3r17C0tLSzFz5kxx7tw5sXLlSiGTycRff/0lhBAiPT1dtwpxSkqKSE9PF0IIERcXJ5YsWSJOnjwpzp07Jz788ENhbGysW/pbCCFCQkKEv7+/OHDggIiNjRW9e/cWJiYm4quvvtIr88QTT4jDhw+Lc+fOiSlTpgg7Oztx48aNSu9jXl6ecHFxEU8//bQ4efKkiIqKEl5eXrrVPm/duiWWL18uAIiUlJQqV/NNSkoSarVahIeHi7Nnz4rVq1cLJycnAUDcvHlTCCHEtWvXxOeffy6OHTsmLly4IL755huhUCjEwYMHhRBCZGdni+DgYPHKK6/ozlVaWiqKi4vF9OnTxeHDh8XFixfF6tWrhampqVi7dm2VPx/lq5h26NBB/PXXX+L8+fPixo0b4uOPPxZ+fn5i69at4sKFC2L58uVCrVaL6OhoUVpaKn777TcBQCQkJIiUlBSRnZ0thBBi3bp14rfffhOJiYni2LFj4oknnhDt27cXGo1GCCHEpUuXBABx7NgxvfMHBQWJ6Ohocfr0adGzZ0/RrVs3XYy7d+8WlpaWYsWKFeLChQvir7/+Ep6enmLmzJlCCCE0Go1o166d6N+/v4iLixN///236NSpkwAgNmzYUOW1ExmCSQhRDdydhGi1WrF9+3ahVqvF22+/La5cuSIUCoVITk7WO6Z///4iIiJCCCF0D9a4uDjd/oSEBAFAbN++vdJzzp49WwwcOFBv29WrV3UPLSHKkpAePXrolenSpYuYOnWq7nt1HyJt27YVCxYsEEIIER8fLwCIw4cP6/YnJiYKALokZM+ePcLS0lIUFhbq1ePj4yO+/fbbSs/x3XffCRsbG5GXl6fbtnnzZiGXy0VqaqoQQogNGzaIB/29FBERIdq0aaO3berUqXpJSGWGDBkipkyZovveu3dvMXny5PueSwghJk6cKJ555pkq95cnARs3btRtKywsFKampmL//v16ZV966SUxatQovePuF7MQQmRkZAgA4uTJk0KIqpOQHTt26I7ZvHmzACBu374thCj7efzkk0/06l21apVwcXERQgixbds2oVQq9X6O//zzTyYhVKfYJ4Sohv744w+Ym5ujpKQEWq0Wzz//PGbOnIno6GhoNBq0bNlSr3xRURHs7Ox031UqFTp06KD7HhcXB4VCgd69e1d6vuPHj2PXrl0wNzevsO/ChQu6891dJwC4uLggPT39vteSl5eHmTNnYvPmzUhJSUFpaSlu376NpKQkAEBCQgKUSiU6d+6sO8bX1xc2NjZ68eXl5eldIwDcvn1b79XB3eLj49GxY0eYmZnptnXv3h1arRYJCQlwcnK6b9x31xMUFKS3LTg4WO+7RqPBJ598gl9++QXJyckoLi5GUVERTE1NH1j/okWL8P333yMpKQm3b99GcXEx/P39H3hcYGCg7r/Pnz+PgoICDBgwQK9McXExOnXqdN96EhMTMX36dBw8eBCZmZnQarUAgKSkpPt2Rr37Z8HFxQUAkJ6ejubNm+P48ePYt28f5syZoyuj0WhQWFiIgoICxMfHw93dHa6urrr9995TotpiEkJUQ3379sXixYuhUqng6uqq63SYl5cHhUKB2NhYKBQKvWPuTiBMTEz0+jiYmJjc93x5eXl44oknMHfu3Ar7yh8wAGBkZKS3TyaT6R5aVXn77bexfft2fPHFF/D19YWJiQmGDx+O4uLi+x53b3wuLi56fV/KWVtbV7ue+vL555/j66+/xvz589G+fXuYmZnhrbfeeuA1rlmzBm+//TbmzZuH4OBgWFhY4PPPP8fBgwcfeM67k6vyfi6bN2+Gm5ubXjm1Wn3fep544gl4eHhg6dKlcHV1hVarRbt27R4Y+90/C+U/a+U/C3l5eZg1axaefvrpCscZGxvft16iusIkhKiGzMzM4OvrW2F7p06doNFokJ6ejp49e1a7vvbt20Or1eLvv/9GSEhIhf2dO3fGb7/9Bk9Pz1qNsjAyMoJGo9Hbtm/fPowfPx5PPfUUgLIH1N0dO1u1aoXS0lIcO3YMAQEBAMr+sr9586ZefKmpqVAqlboOrw/SunVrrFixAvn5+boH9r59+yCXy9GqVatqX1Pr1q11nYLLHThwoMI1Dh06FC+88AKAsofxuXPn0KZNG10ZlUpV6b3p1q0bJkyYoNtWVcvO/dzdAbmq1i6VSgUAejHcuHEDCQkJWLp0qe7nae/evQaf/16dO3dGQkJCpT/DQNk9vXr1KlJSUnRJ7r33lKi2ODqGqI61bNkSo0ePxtixY7F+/XpcunQJhw4dQmRkJDZv3lzlcZ6enhg3bhxefPFFbNy4EZcuXUJ0dDR++eUXAMDEiRORlZWFUaNG4fDhw7hw4QK2bduGsLCwCg/O+/H09ERUVBRSU1N1SUSLFi2wfv16xMXF4fjx43j++ef1Wk/8/PwQEhKCV199FYcOHcKxY8fw6quv6rXmhISEIDg4GMOGDcNff/2Fy5cvY//+/fjggw9w5MiRSmMZPXo0jI2NMW7cOJw6dQq7du3CpEmTMGbMmGq/igGA1157DYmJiXjnnXeQkJCAn376CStWrNAr06JFC2zfvh379+9HfHw8/vWvfyEtLa3CvTl48CAuX76se+3RokULHDlyBNu2bcO5c+cwbdo0HD58uNqxlbOwsMDbb7+Nf//731i5ciUuXLiAo0ePYsGCBVi5ciUAwMPDAzKZDH/88QcyMjKQl5cHGxsb2NnZ4bvvvsP58+exc+dOhIeHG3z+e02fPh0//PADZs2ahdOnTyM+Ph5r1qzBhx9+CKDs37Nly5YYN24cjh8/jj179uCDDz6o9XmJ9EjdKYWoKapsdMzdykdUeHp6/n/7ds/SOhSAcfwUTGNAbSlYWiF0Cb4M2k2ktEPpIE6lsyAuDg6CLiLi5Cfo0EEcurUfQJdCReonELq1QwVRO7mooCD0fwe54RZvoVwuBOH5reckOTlneQhPsCyLZDJJqVSi3W4DX8XUSCTy7br393cODg5IJpOEw2E8z6Narfrj3W6XUqlENBrFcRwWFxfZ399nMBgAfy9WFotF/28TgIuLCzzPY2JiglQqBXwVG/P5PI7j4LoulUrl272enp7Y2NjAtm1SqRT1ep14PM7Z2Zk/5+Xlhb29Pebm5rAsC9d12dzc5P7+fuRetdtt8vk8k5OTxGIxdnZ2eH199cfHKaYCXF5e4nketm2Ty+WoVqtDJc/n52eKxSJTU1PE43FOTk7Y2toaOsdOp8Pa2hqO42CM4e7ujo+PD7a3t4lEIkSjUXZ3dzk6OiKdTo9cy6iC6WAwoFwus7CwgGVZzM7Osr6+zs3NjT/n9PSURCJBKBTyz63ZbLK0tIRt26ysrNBqtYYKoqOKqX8+//b21n+n3xqNBplMBsdxmJmZYXV1lfPz86H9yGazhMNh5ufnaTQaKqbKfxUCCCwBiciP9fDwYFzXNVdXV6ZQKAS9HBH5gRRCRGQs19fX5u3tzSwvL5t+v28ODw/N4+Oj6Xa738qwIiLjUDFVRMby+flpjo+PTa/XM9PT0yaTyZharaYAIiL/TF9CREREJBD6O0ZEREQCoRAiIiIigVAIERERkUAohIiIiEggFEJEREQkEAohIiIiEgiFEBEREQmEQoiIiIgE4hcl1gDozBJUyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "with open(\"local/correct_list.pkl\", \"rb\") as f:\n",
    "    correct_list = pickle.load(f)\n",
    "with open(\"local/uncertainty_list.pkl\", \"rb\") as f:\n",
    "    uncertainty_list = pickle.load(f)\n",
    "\n",
    "def plot_retention_curve(correct_list, uncertainty_list):\n",
    "    # Sort examples by uncertainty\n",
    "    sorted_indices = np.argsort(uncertainty_list)\n",
    "    correct_list = np.array(correct_list)[sorted_indices]\n",
    "    uncertainty_list = np.array(uncertainty_list)[sorted_indices]\n",
    "\n",
    "    # Calculate cumulative accuracy\n",
    "    cumulative_correct = np.cumsum(correct_list)\n",
    "    cumulative_total = np.arange(1, len(correct_list) + 1)\n",
    "    accuracy = cumulative_correct / cumulative_total\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_accuracy = gaussian_filter1d(accuracy, sigma=100)\n",
    "\n",
    "    # Calculate percentage of data retained\n",
    "    data_percentage = np.linspace(0, 100, len(correct_list))\n",
    "\n",
    "    # Plot retention curve\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(data_percentage, smoothed_accuracy, label='Cumulative Accuracy (Smoothed)')\n",
    "    # plt.plot(data_percentage, accuracy, alpha=0.3, label='Raw Cumulative Accuracy')\n",
    "    plt.xlabel('Percentage of data retained')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Retention Curve')\n",
    "    plt.ylim(0.28, 0.37)  # Set y-axis limits between 0.3 and 0.4\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_retention_curve(correct_list, uncertainty_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
