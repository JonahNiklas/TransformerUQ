{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcd224b5f7041ecb3de9817a2b9583f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonah\\Documents\\gitRepos\\TransformerUQ\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jonah\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d147c76d7684e049a707186949e34fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34885bc42114c2c905a551ff24bedab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = nn.GELU(approximate='tanh')\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024 # max sequence length\n",
    "    vocab_size: int = 50257 # number of tokens: 50,000 BPE merges + 256 bytes tokens + 1 <|endoftext|> token\n",
    "    n_layer: int = 12 # number of layers\n",
    "    n_head: int = 12 # number of heads\n",
    "    n_embd: int = 768 # embedding dimension\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight sharing scheme\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # init params\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is of shape (B, T)\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
    "        # forward the token and posisition embeddings\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device) # shape (T)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (B, T, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        # forward the blocks of the transformer\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        # forward the final layernorm and the classifier\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gpt2 = GPT.from_pretrained('gpt2').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 24/24 [03:08<00:00,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Hello, I'm a language model, so I don't require the code to compile and compile for me because I have more to do.\n",
      "\n",
      "I'm\n",
      "sample 1: Hello, I'm a language model, the way it works. You must understand the grammar and language, and you must understand what I mean by grammar. You\n",
      "sample 2: Hello, I'm a language model, I'm not a person,\" he said. \"This is an important thing to have and to have knowledge of.\"\n",
      "\n",
      "sample 3: Hello, I'm a language model, a compiler. And it's something I'd like to have a little bit of conversation about.\" He pauses between tears,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = \"cuda\" if \"cuda\" in device else \"cpu\"\n",
    "\n",
    "def generate_from_model(model, context, max_tokens=100):\n",
    "    model.eval()\n",
    "    num_return_sequences = 4\n",
    "    max_length = 32\n",
    "    tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "    xgen = tokens.to(device)\n",
    "    sample_rng = torch.Generator(device=device)\n",
    "    pbar = tqdm(total=max_length - xgen.size(1), desc=\"Generating\")\n",
    "    while xgen.size(1) < max_length:\n",
    "        # forward the model to get the logits\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "                logits, loss = model(xgen) # (B, T, vocab_size)\n",
    "            # take the logits at the last position\n",
    "            logits = logits[:, -1, :] # (B, vocab_size)\n",
    "            # get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # do top-k sampling of 50 (huggingface pipeline default)\n",
    "            # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "            # select a token from the top-k probabilities\n",
    "            # note: multinomial does not demand the input to sum to 1\n",
    "            ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "            # gather the corresponding indices\n",
    "            xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "            # append to the sequence\n",
    "            xgen = torch.cat((xgen, xcol), dim=1)\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    # print the generated text\n",
    "    for i in range(num_return_sequences):\n",
    "        tokens = xgen[i, :max_length].tolist()\n",
    "        decoded = enc.decode(tokens)\n",
    "        print(f\"sample {i}: {decoded}\")\n",
    "\n",
    "\n",
    "generate_from_model(gpt2, \"Hello, I'm a language model,\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'uq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2LMHeadModel\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01muq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01macquisition_func\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeamScore\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01muq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerate_with_uq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _enable_test_time_dropout\n\u001b[0;32m     42\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'uq'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloads and evaluates HellaSwag in Python.\n",
    "https://github.com/rowanz/hellaswag\n",
    "\n",
    "Example HellaSwag json item:\n",
    "\n",
    "{\"ind\": 24, \"activity_label\": \"Roof shingle removal\", \"ctx_a\": \"A man is sitting on a roof.\", \"ctx_b\": \"he\", \"ctx\": \"A man is sitting on a roof. he\", \"split\": \"val\", \"split_type\": \"indomain\", \"label\": 3, \"endings\": [\"is using wrap to wrap a pair of skis.\", \"is ripping level tiles off.\", \"is holding a rubik's cube.\", \"starts pulling up roofing on a roof.\"], \"source_id\": \"activitynet~v_-JhWjGDPHMY\"}\n",
    "\n",
    "ind: dataset ID\n",
    "activity_label: The ActivityNet or WikiHow label for this example\n",
    "context: There are two formats. The full context is in ctx. When the context ends in an (incomplete) noun phrase, like for ActivityNet, this incomplete noun phrase is in ctx_b, and the context up until then is in ctx_a. This can be useful for models such as BERT that need the last sentence to be complete. However, it's never required. If ctx_b is nonempty, then ctx is the same thing as ctx_a, followed by a space, then ctx_b.\n",
    "endings: a list of 4 endings. The correct index is given by label (0,1,2, or 3)\n",
    "split: train, val, or test.\n",
    "split_type: indomain if the activity label is seen during training, else zeroshot\n",
    "source_id: Which video or WikiHow article this example came from\n",
    "\n",
    "gpt2 (124M)\n",
    "- eleuther harness reports acc 28.92%, acc_norm 31.14% (multiple choice style)\n",
    "- this script: 10042 acc: 0.2859 acc_norm: 0.2955 (completion style)\n",
    "\n",
    "gpt2-xl (1558M)\n",
    "- eleuther harness reports acc 40.04%, acc_norm 50.89% (multiple choice style)\n",
    "- this script: 10042 acc: 0.3842 acc_norm: 0.4893 (completion style)\n",
    "\n",
    "The validation set of HellaSwag has a total of 10,042 examples.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import tiktoken\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "from uq.acquisition_func import BeamScore\n",
    "from uq.generate_with_uq import _enable_test_time_dropout\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = \"cuda\" if \"cuda\" in device else \"cpu\"\n",
    "# -----------------------------------------------------------------------------\n",
    "DATA_CACHE_DIR = os.path.join(os.getcwd(), \"local/hellaswag\")\n",
    "\n",
    "def download_file(url: str, fname: str, chunk_size=1024):\n",
    "    \"\"\"Helper function to download a file from a given url\"\"\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    total = int(resp.headers.get(\"content-length\", 0))\n",
    "    with open(fname, \"wb\") as file, tqdm(\n",
    "        desc=fname,\n",
    "        total=total,\n",
    "        unit=\"iB\",\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "hellaswags = {\n",
    "    \"train\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_train.jsonl\",\n",
    "    \"val\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_val.jsonl\",\n",
    "    \"test\": \"https://raw.githubusercontent.com/rowanz/hellaswag/master/data/hellaswag_test.jsonl\",\n",
    "}\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def download(split):\n",
    "    \"\"\"Downloads HellaSwag DATA_CACHE_DIR\"\"\"\n",
    "    os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "    data_url = hellaswags[split]\n",
    "    data_filename = os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\")\n",
    "    if not os.path.exists(data_filename):\n",
    "        print(f\"Downloading {data_url} to {data_filename}...\")\n",
    "        download_file(data_url, data_filename)\n",
    "\n",
    "def render_example(example):\n",
    "    \"\"\"\n",
    "    Given the example as a dictionary, render it as three torch tensors:\n",
    "    - tokens (the tokens of context + completion, of size 4xN, as there are always 4 candidates)\n",
    "    - mask (is 1 in the region of the candidate completion, where we evaluate likelihoods)\n",
    "    - label (the index of the correct completion, which we hope has the highest likelihood)\n",
    "    \"\"\"\n",
    "    ctx = example[\"ctx\"]\n",
    "    label = example[\"label\"]\n",
    "    endings = example[\"endings\"]\n",
    "\n",
    "    # data needed to reproduce this eval on the C size\n",
    "    data = {\n",
    "        \"label\": label,\n",
    "        \"ctx_tokens\": None,\n",
    "        \"ending_tokens\": [],\n",
    "    }\n",
    "\n",
    "    # gather up all the tokens\n",
    "    ctx_tokens = enc.encode(ctx)\n",
    "    data[\"ctx_tokens\"] = ctx_tokens\n",
    "    tok_rows = []\n",
    "    mask_rows = []\n",
    "    for end in endings:\n",
    "        end_tokens = enc.encode(\" \" + end) # note: prepending \" \" because GPT-2 tokenizer\n",
    "        tok_rows.append(ctx_tokens + end_tokens)\n",
    "        mask_rows.append([0]*len(ctx_tokens) + [1]*len(end_tokens))\n",
    "        data[\"ending_tokens\"].append(end_tokens)\n",
    "\n",
    "    # have to be careful during the collation because the number of tokens in each row can differ\n",
    "    max_len = max(len(row) for row in tok_rows)\n",
    "    tokens = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    mask = torch.zeros((4, max_len), dtype=torch.long)\n",
    "    for i, (tok_row, mask_row) in enumerate(zip(tok_rows, mask_rows)):\n",
    "        tokens[i, :len(tok_row)] = torch.tensor(tok_row)\n",
    "        mask[i, :len(mask_row)] = torch.tensor(mask_row)\n",
    "\n",
    "    return data, tokens, mask, label\n",
    "\n",
    "def iterate_examples(split):\n",
    "    # there are 10,042 examples in total in val\n",
    "    download(split)\n",
    "    with open(os.path.join(DATA_CACHE_DIR, f\"hellaswag_{split}.jsonl\"), \"r\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            yield example\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model_type, device):\n",
    "\n",
    "    torch.set_float32_matmul_precision('high') # use tf32\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "    model.to(device)\n",
    "    # model = torch.compile(model) # optionally torch compile the model\n",
    "\n",
    "    num_correct_norm = 0\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for example in iterate_examples(\"val\"):\n",
    "        data, tokens, mask, label = render_example(example)\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        # get the logits\n",
    "        logits = model(tokens).logits\n",
    "        # evaluate the autoregressive loss at all positions\n",
    "        shift_logits = (logits[..., :-1, :]).contiguous()\n",
    "        shift_tokens = (tokens[..., 1:]).contiguous()\n",
    "        flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "        flat_shift_tokens = shift_tokens.view(-1)\n",
    "        shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
    "        shift_losses = shift_losses.view(tokens.size(0), -1)\n",
    "        # now get the average loss just for the completion region (where mask == 1), in each row\n",
    "        shift_mask = (mask[..., 1:]).contiguous() # we must shift mask, so we start at the last prompt token\n",
    "        masked_shift_losses = shift_losses * shift_mask\n",
    "        # sum and divide by the number of 1s in the mask\n",
    "        sum_loss = masked_shift_losses.sum(dim=1)\n",
    "        avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "        # now we have a loss for each of the 4 completions\n",
    "        # the one with the lowest loss should be the most likely\n",
    "        pred = sum_loss.argmin().item()\n",
    "        pred_norm = avg_loss.argmin().item()\n",
    "\n",
    "        # accumulate stats\n",
    "        num_total += 1\n",
    "        num_correct += int(pred == label)\n",
    "        num_correct_norm += int(pred_norm == label)\n",
    "        print(f\"{num_total} acc_norm: {num_correct_norm}/{num_total}={num_correct_norm/num_total:.4f}\")\n",
    "\n",
    "        # debug: pretty print a few examples, and the losses in each case\n",
    "        if num_total < 10:\n",
    "            print(\"---\")\n",
    "            print(f\"Context:\\n {example['ctx']}\")\n",
    "            print(f\"Endings:\")\n",
    "            for i, end in enumerate(example[\"endings\"]):\n",
    "                print(f\"{i} (loss: {avg_loss[i].item():.4f}) {end}\")\n",
    "            print(f\"predicted: {pred_norm}, actual: {label}\")\n",
    "\n",
    "\n",
    "def get_most_likely_row(tokens, mask, logits):\n",
    "    # evaluate the autoregressive loss at all positions\n",
    "    shift_logits = (logits[..., :-1, :]).contiguous()\n",
    "    shift_tokens = (tokens[..., 1:]).contiguous()\n",
    "    flat_shift_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "    flat_shift_tokens = shift_tokens.view(-1)\n",
    "    shift_losses = F.cross_entropy(flat_shift_logits, flat_shift_tokens, reduction='none')\n",
    "    shift_losses = shift_losses.view(tokens.size(0), -1)\n",
    "    # now get the average loss just for the completion region (where mask == 1), in each row\n",
    "    shift_mask = (mask[..., 1:]).contiguous() # we must shift mask, so we start at the last prompt token\n",
    "    masked_shift_losses = shift_losses * shift_mask\n",
    "    # sum and divide by the number of 1s in the mask\n",
    "    sum_loss = masked_shift_losses.sum(dim=1)\n",
    "    avg_loss = sum_loss / shift_mask.sum(dim=1)\n",
    "    # now we have a loss for each of the 4 completions\n",
    "    # the one with the lowest loss should be the most likely\n",
    "    pred_norm = avg_loss.argmin().item()\n",
    "\n",
    "    return pred_norm\n",
    "\n",
    "\n",
    "def get_uncertainty_of_selected_tokens(tokens, mask, logits):\n",
    "    logits = F.log_softmax(logits, dim=-1)\n",
    "    logits_of_selected_tokens = torch.gather(logits, -1, tokens.unsqueeze(-1)).squeeze(-1)\n",
    "    logits_of_selected_tokens[~mask] = 0\n",
    "    # Find uncertainty for the most likely row\n",
    "    uncertainty = BeamScore()(tokens.unsqueeze(0), logits_of_selected_tokens.unsqueeze(0))\n",
    "    assert uncertainty.shape == (1,)\n",
    "    return uncertainty.item()\n",
    "\n",
    "def get_uncertainty_of_selected_tokens_mcdo(model, tokens, mask, num_mc_samples=10):\n",
    "    \"\"\"\n",
    "    Computes uncertainty using Monte Carlo dropout (MCdo).\n",
    "    \n",
    "    This function runs several stochastic forward passes with dropout enabled\n",
    "    so that the resulting log probabilities for the tokens in the completion region\n",
    "    will vary. The variance of these log probabilities is taken as our uncertainty measure.\n",
    "    \n",
    "    Args:\n",
    "      model: The language model to use.\n",
    "      tokens: A 1D torch.Tensor of token IDs (of shape (T,)) for one candidate completion.\n",
    "      mask: A 1D torch.Tensor of the same length as tokens, where 1 indicates a token that is \n",
    "            part of the completion (and 0 indicates context tokens that are ignored).\n",
    "      num_mc_samples: Number of MC dropout forward passes.\n",
    "    \n",
    "    Returns:\n",
    "      A scalar uncertainty value (a higher value indicates higher uncertainty).\n",
    "    \"\"\"\n",
    "    # Save the current training/eval mode and enable dropout.\n",
    "    _enable_test_time_dropout(model)\n",
    "    \n",
    "    mc_samples = []\n",
    "    # Our model expects a batch dimension, so add one.\n",
    "    tokens = tokens.unsqueeze(0)  # shape: (1, T)\n",
    "    \n",
    "    for _ in range(num_mc_samples):\n",
    "        with torch.no_grad():\n",
    "            # Perform a forward pass (dropout is active because model is in training mode)\n",
    "            logits, _ = model(tokens)  # logits has shape: (1, T, vocab_size)\n",
    "        logits = logits.squeeze(0)  # Remove the batch dimension, now (T, vocab_size)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)  # (T, vocab_size)\n",
    "        # Gather the log-probabilities for the provided token sequence.\n",
    "        selected_log_probs = torch.gather(log_probs, -1, tokens.squeeze(0).unsqueeze(-1)).squeeze(-1)  # (T,)\n",
    "        # Only consider tokens in the completion region (mask==1)\n",
    "        selected_log_probs = selected_log_probs[mask.bool()]\n",
    "        mc_samples.append(selected_log_probs)\n",
    "        \n",
    "    mc_samples = torch.stack(mc_samples, dim=0)  # Shape: (num_mc_samples, L)\n",
    "    # Compute the variance across the MC samples for each token in the completion region.\n",
    "    token_variances = torch.var(mc_samples, dim=0)\n",
    "    # Average the per-token variance to yield a single uncertainty measure.\n",
    "    uncertainty = token_variances.mean()\n",
    "    \n",
    "    return uncertainty.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_hellaswag(model):\n",
    "    num_correct_norm = 0\n",
    "    num_total = 0\n",
    "\n",
    "    correct_list = []\n",
    "    uncertainty_list = []\n",
    "    pbar = tqdm(total=10042, desc=\"Evaluating HellaSwag\")    \n",
    "    for i, example in enumerate(iterate_examples(\"val\")):\n",
    "        # Render the example into tokens, mask, and label.\n",
    "        _, tokens, mask, label = render_example(example)\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # Obtain a forward pass from the model.\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device_type, dtype=torch.bfloat16):\n",
    "                logits, loss = model(tokens)\n",
    "            # Use the existing routine to choose the candidate with the lowest (average) loss.\n",
    "            pred_norm = get_most_likely_row(tokens, mask, logits)\n",
    "            # Compute uncertainty via MC dropout for the selected candidate row.\n",
    "            uncertainty = get_uncertainty_of_selected_tokens(tokens[pred_norm], mask[pred_norm], logits[pred_norm])\n",
    "            # uncertainty = get_uncertainty_of_selected_tokens_mcdo(model, tokens[pred_norm], mask[pred_norm])\n",
    "        num_total += 1\n",
    "        num_correct_norm += int(pred_norm == label)\n",
    "\n",
    "        correct_list.append(int(pred_norm == label))\n",
    "        uncertainty_list.append(uncertainty)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'acc': f'{num_correct_norm/num_total:.4f}'})\n",
    "    \n",
    "    pbar.close()\n",
    "    acc_norm = num_correct_norm / num_total\n",
    "    print(f\"HellaSwag accuracy: {num_correct_norm}/{num_total}={acc_norm:.4f}\")\n",
    "\n",
    "    # Save the correctness and uncertainty lists to files for later analysis.\n",
    "    with open(\"local/correct_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(correct_list, f)\n",
    "    with open(\"local/uncertainty_list.pkl\", \"wb\") as f:\n",
    "        pickle.dump(uncertainty_list, f)\n",
    "\n",
    "evaluate_hellaswag(gpt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "with open(\"local/correct_list.pkl\", \"rb\") as f:\n",
    "    correct_list = pickle.load(f)\n",
    "with open(\"local/uncertainty_list.pkl\", \"rb\") as f:\n",
    "    uncertainty_list = pickle.load(f)\n",
    "\n",
    "def plot_retention_curve(correct_list, uncertainty_list):\n",
    "    # Sort examples by uncertainty\n",
    "    sorted_indices = np.argsort(uncertainty_list)\n",
    "    correct_list = np.array(correct_list)[sorted_indices]\n",
    "    uncertainty_list = np.array(uncertainty_list)[sorted_indices]\n",
    "\n",
    "    # Calculate cumulative accuracy\n",
    "    cumulative_correct = np.cumsum(correct_list)\n",
    "    cumulative_total = np.arange(1, len(correct_list) + 1)\n",
    "    accuracy = cumulative_correct / cumulative_total\n",
    "\n",
    "    # Apply Gaussian smoothing\n",
    "    smoothed_accuracy = gaussian_filter1d(accuracy, sigma=100)\n",
    "\n",
    "    # Calculate percentage of data retained\n",
    "    data_percentage = np.linspace(0, 100, len(correct_list))\n",
    "\n",
    "    # Plot retention curve\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(data_percentage, smoothed_accuracy, label='Cumulative Accuracy (Smoothed)')\n",
    "    # plt.plot(data_percentage, accuracy, alpha=0.3, label='Raw Cumulative Accuracy')\n",
    "    plt.xlabel('Percentage of data retained')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Retention Curve')\n",
    "    # plt.ylim(0.28, 0.37)  # Set y-axis limits between 0.3 and 0.4\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_retention_curve(correct_list, uncertainty_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
